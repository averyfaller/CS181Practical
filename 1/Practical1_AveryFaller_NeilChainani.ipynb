{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the DataFrame\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "# Row where testing examples start\n",
    "test_idx = df_train.shape[0]\n",
    "# Delete 'Id' column\n",
    "df_test = df_test.drop(['Id'], axis=1)\n",
    "# Delete 'gap' column\n",
    "df_train = df_train.drop(['gap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_247</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...         0         0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...         1         0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...         1         0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...         1         0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1         0         0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  \\\n",
       "0         0         0         1         0         1         0         0   \n",
       "1         0         0         1         0         1         0         0   \n",
       "2         0         0         1         1         1         0         0   \n",
       "3         0         0         1         1         1         0         0   \n",
       "4         0         0         1         0         1         0         0   \n",
       "\n",
       "     ...     feat_247  feat_248  feat_249  feat_250  feat_251  feat_252  \\\n",
       "0    ...            0         1         0         0         0         0   \n",
       "1    ...            0         1         0         0         1         0   \n",
       "2    ...            0         1         0         0         0         1   \n",
       "3    ...            0         1         0         0         0         1   \n",
       "4    ...            0         1         0         0         0         0   \n",
       "\n",
       "   feat_253  feat_254  feat_255  feat_256  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 257 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame with all train and test examples so we can more easily apply feature engineering on\n",
    "df_all = pd.concat((df_train, df_test), axis=0)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A method to make features on a supplied DataFrame\n",
    "def makeFeatures(df):\n",
    "    \n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "    \n",
    "    ###########################\n",
    "    ### FEATURE ENGINEERING ###\n",
    "    ###########################\n",
    "    # Add length of smile\n",
    "    df['smile_length'] = df.smiles.map(lambda x: len(x))\n",
    "\n",
    "    # Add number of C's divided by length\n",
    "    df['smile_percentc'] = (df.smile_c / df.smile_length)\n",
    "    df['smile_percentC'] = (df.smile_C / df.smile_length)\n",
    "\n",
    "    # Count specific molecules\n",
    "    # [nH]\n",
    "    df['smile_nh'] = df.smiles.map(lambda x: '[nH]' in x)\n",
    "    df['smile_nh1'] = df.smiles.map(lambda x: '[nH]1' in x)\n",
    "    df['smile_si'] = df.smiles.map(lambda x: 'Si' in x)\n",
    "    df['smile_sih2'] = df.smiles.map(lambda x: '[SiH2]' in x)\n",
    "    df['smile_se'] = df.smiles.map(lambda x: '[se]' in x)\n",
    "    df['smile_CdoubleC'] = df.smiles.map(lambda x: 'C=C' in x)\n",
    "    df['smile_doubleC'] = df.smiles.map(lambda x: 'CC' in x)\n",
    "    df['smile_doublec'] = df.smiles.map(lambda x: 'cc' in x)\n",
    "    df['smile_triplec'] = df.smiles.map(lambda x: 'ccc' in x)\n",
    "    df['smile_quadc'] = df.smiles.map(lambda x: 'cccc' in x)\n",
    "    df['smile_quintc'] = df.smiles.map(lambda x: 'ccccc' in x)\n",
    "    df['smile_C1equalCc2'] = df.smiles.map(lambda x: 'C1=Cc2' in x)\n",
    "    df['smile_C1'] = df.smiles.map(lambda x: 'C1' in x)\n",
    "    df['smile_c1'] = df.smiles.map(lambda x: 'c1' in x)\n",
    "    df['smile_equalCCCequal'] = df.smiles.map(lambda x: '=CCC=' in x)\n",
    "    df['smile_equalCCequal'] = df.smiles.map(lambda x: '=CC=' in x)\n",
    "    df['smile_equalCequal'] = df.smiles.map(lambda x: '=C=' in x)\n",
    "    df['smile_C1equalCCequalC'] = df.smiles.map(lambda x: 'C1=CC=C' in x)\n",
    "    df['smile_c1cccs1'] = df.smiles.map(lambda x: 'c1ccc(s1)' in x)\n",
    "\n",
    "    # Important molecules\n",
    "    df['smile_c1ccccc1'] = df.smiles.map(lambda x: 'c1ccccc1' in x)\n",
    "    df['smile_n1ccccc1'] = df.smiles.map(lambda x: 'n1ccccc1' in x)\n",
    "    df['smile_o1cccc1'] = df.smiles.map(lambda x: 'o1cccc1' in x)\n",
    "    df['smile_c1ccccc1-c2ccccc2'] = df.smiles.map(lambda x: 'c1ccccc1-c2ccccc2' in x)\n",
    "    df['smile_n1c[nH]cc1'] = df.smiles.map(lambda x: 'n1c[nH]cc1' in x)\n",
    "    \n",
    "    # Parentheses molecules\n",
    "    df['smile_parenC1'] = df.smiles.map(lambda x: '(C1)' in x)\n",
    "    df['smile_parenc1'] = df.smiles.map(lambda x: '(c1)' in x)\n",
    "    df['smile_parencc1'] = df.smiles.map(lambda x: '(cc1)' in x)\n",
    "    df['smile_pareno1'] = df.smiles.map(lambda x: '(o1)' in x)\n",
    "    df['smile_parens1'] = df.smiles.map(lambda x: '(s1)' in x)\n",
    "    df['smile_parenccc4mol'] = df.smiles.map(lambda x: '(ccc4=C[SiH2]C=c34)' in x)\n",
    "    df['smile_parenccinnermol'] = df.smiles.map(lambda x: '(cc(-c3ccco3)c3=CCC=c13)' in x)\n",
    "    df['smile_parennegc3cco3'] = df.smiles.map(lambda x: '(-c3ccco3)' in x)\n",
    "    df['smile_parenncc3c12'] = df.smiles.map(lambda x: '(ncc3c12)' in x)\n",
    "    df['smile_parenccc34'] = df.smiles.map(lambda x: '(ccc34)' in x)\n",
    "    df['smile_parencc4ccc3c2cn1'] = df.smiles.map(lambda x: '(cc4ccc3c2cn1)' in x)\n",
    "\n",
    "    # Special\n",
    "    df['smile_percent_aromatic'] = (df.smile_c + df.smile_o + df.smile_n + df.smile_s / df.smile_length)\n",
    "\n",
    "    # Start\n",
    "    df['smile_start_C1'] = df.smiles.map(lambda x: x.startswith('C1'))\n",
    "    df['smile_start_C1equal'] = df.smiles.map(lambda x: x.startswith('C1='))\n",
    "    df['smile_start_c1'] = df.smiles.map(lambda x: x.startswith('c1'))\n",
    "    df['smile_start_cc1'] = df.smiles.map(lambda x: x.startswith('cc1'))\n",
    "    df['smile_start_c1sc'] = df.smiles.map(lambda x: x.startswith('c1sc'))\n",
    "    df['smile_start_c1ccc'] = df.smiles.map(lambda x: x.startswith('c1ccc'))\n",
    "    df['smile_start_nH'] = df.smiles.map(lambda x: x.startswith('[nH]'))\n",
    "    df['smile_start_C1equalCCequalC'] = df.smiles.map(lambda x: x.startswith('C1=CC=C'))\n",
    "\n",
    "    # End\n",
    "    df['smile_end_c1ccc'] = df.smiles.map(lambda x: x.endswith('c1ccc'))\n",
    "    df['smile_end_o1'] = df.smiles.map(lambda x: x.endswith('o1'))\n",
    "    df['smile_end_ccsc12'] = df.smiles.map(lambda x: x.endswith('ccsc12'))\n",
    "    \n",
    "    joint = ''.join(smiles.iloc[:3000])\n",
    "    \n",
    "    ###############\n",
    "    ### BIGRAMS ###\n",
    "    ###############\n",
    "    top_50_bigrams = Counter(zip(joint,joint[1:])).most_common(200)\n",
    "    for bigram,count in top_50_bigrams:\n",
    "        b = bigram[0]+bigram[1]+\"\"\n",
    "        df[b+\"_bigram\"] = smiles.map(lambda x: 1 if b in x else 0)\n",
    "        \n",
    "    ################\n",
    "    ### TRIGRAMS ###\n",
    "    ################\n",
    "    top_trigrams = Counter(zip(joint, joint[1:], joint[2:])).most_common(200)\n",
    "    for trigram, count in top_trigrams:\n",
    "        t = trigram[0]+trigram[1]+trigram[2]+\"\"\n",
    "        df[t+\"_trigram\"] = smiles.map(lambda x: 1 if t in x else 0)\n",
    "        \n",
    "    ################\n",
    "    ### QUADGRAMS ###\n",
    "    ################\n",
    "    top_quadgrams = Counter(zip(joint, joint[1:], joint[2:], joint[3:])).most_common(200)\n",
    "    for quadgram, count in top_quadgrams:\n",
    "        q = quadgram[0]+quadgram[1]+quadgram[2]+quadgram[3]+\"\"\n",
    "        df[q+\"_quadgram\"] = smiles.map(lambda x: 1 if q in x else 0)\n",
    "        \n",
    "    ################\n",
    "    ### QUINTS ###\n",
    "    ################\n",
    "    top_quintgrams = Counter(zip(joint, joint[1:], joint[2:], joint[3:], joint[4:])).most_common(100)\n",
    "    for quintgram, count in top_quintgrams:\n",
    "        q = quintgram[0]+quintgram[1]+quintgram[2]+quintgram[3]+quintgram[4]+\"\"\n",
    "        df[q+\"_quintgram\"] = smiles.map(lambda x: 1 if q in x else 0)\n",
    "        \n",
    "    ###########\n",
    "    ### SIX ###\n",
    "    ###########\n",
    "    top_sixgrams = Counter(zip(joint, joint[1:], joint[2:], joint[3:], joint[4:], joint[5:])).most_common(100)\n",
    "    for sixgram, count in top_sixgrams:\n",
    "        s = sixgram[0]+sixgram[1]+sixgram[2]+sixgram[3]+sixgram[4]+sixgram[5]+\"\"\n",
    "        df[s+\"_sixgram\"] = smiles.map(lambda x: 1 if s in x else 0)\n",
    "    \n",
    "    ################################\n",
    "    ### DROP UNNECESSARY COLUMNS ###\n",
    "    ################################   \n",
    "    df = df.drop('smile_length', axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1824230, 858)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the features\n",
    "print \"Making Features\"\n",
    "df_all = makeFeatures(df_all)\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 857)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 857)\n"
     ]
    }
   ],
   "source": [
    "# Split the train and test sets\n",
    "df_all = df_all.drop(['smiles'], axis=1)\n",
    "vals = df_all.values\n",
    "X_train = vals[:test_idx]\n",
    "X_test = vals[test_idx:]\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into Train, Validation & Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create temporary train, validate and test sets from the X_train set\n",
    "X_tmp_trainvalidate, X_tmp_test, Y_tmp_trainvalidate, Y_tmp_test = train_test_split(X_train, Y_train, test_size=0.20, random_state=37)\n",
    "X_tmp_train, X_tmp_validate, Y_tmp_train, Y_tmp_validate = train_test_split(X_tmp_trainvalidate, Y_tmp_trainvalidate, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating the Data\n",
    "Here we record the results of various tests and their resultant RMSE values on the validation set.\n",
    "\n",
    "### Basic RF with SMILE Character Counts\n",
    " Validation RMSE for n = 10: 0.144<br/>\n",
    " Validation RMSE for n = 15: 0.142<br/>\n",
    " Validation RMSE for n = 20: 0.142<br/>\n",
    " Validation RMSE for n = 30: 0.141<br/>\n",
    " Validation RMSE for n = 40: 0.141\n",
    " \n",
    " The best N for RF was: 40 with RMSE: .141\n",
    "\n",
    "### Basic RF with Empty Columns Dropped\n",
    "Validation RMSE for n = 10: 0.1436\n",
    "\n",
    "### Basic RF with Feature Engineering\n",
    "Validation RMSE for n = 10: 0.1293<br/>\n",
    "Validation RMSE for n = 30: 0.1263<br/>\n",
    "Validation RMSE for n = 40: 0.1260\n",
    "\n",
    "### Basic RF with Feature Engineering and min_samples_split testing\n",
    "Validation RMSE for n = 10, min_samples_split = 2: 0.1296 <br/>\n",
    "Validation RMSE for n = 10, min_samples_split = 5: 0.1267<br/>\n",
    "Validation RMSE for n = 10, min_samples_split = 8: 0.1259<br/>\n",
    "Validation RMSE for n = 10, min_samples_split = 12: 0.1255<br/>\n",
    "Validation RMSE for n = 10, min_samples_split = 15: 0.1264<br/>\n",
    "\n",
    "Validation RMSE for n = 30, min_samples_split = 12: 0.1233<br/>\n",
    "\n",
    "Validation RMSE for n = 40, min_samples_split = 12: 0.1230<br/>\n",
    "\n",
    "### Basic RF with Bigrams and min_samples_split testing\n",
    "50 top bigrams: Validation RMSE for n = 40, min_samples_split = 12: 0.1140<br/>\n",
    "100 top bigrams: Validation RMSE for n = 40, min_samples_split = 12: 0.1021<br/>\n",
    "200 top bigrams: Validation RMSE for n = 40, min_samples_split = 12: 0.1011\n",
    "\n",
    "### Basic RF with Bigrams, Trigrams and min_samples_split testing\n",
    "100 top bigrams + 100 top trigrams: Validation RMSE for n = 40, min_samples_split = 12: 0.0864\n",
    "\n",
    "### Basic RF with Bigrams, Trigrams, Quadgrams and min_samples_split testing\n",
    "100 top bigrams + 100 top trigrams + 100 top quadgrams: Validation RMSE for n = 40, min_samples_split = 12: 0.0819<br/>\n",
    "200 top bigrams + 100 top trigrams + 100 top quadgrams: Validation RMSE for n = 40, min_samples_split = 12: 0.0809\n",
    "\n",
    "### Basic RF with Quints\n",
    "200 top bigrams + 200 top trigrams + 100 top quadgrams + 100 top quintgrams: Validation RMSE for n = 40, min_samples_split = 12: 0.0778<br/>\n",
    "200 top bigrams + 200 top trigrams + 100 top quadgrams + 100 top quintgrams: Validation RMSE for n = 50, min_samples_split = 12: 0.0777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE for n = 50, min_samples_split = 12: 0.0769\n",
      "The best N for RF was: 50, with min_samples_split: 12, with RMSE: 0.0769\n"
     ]
    }
   ],
   "source": [
    "# Validate and tune the Random Forest Regressor\n",
    "bestRFValidateRMSE = 1.0\n",
    "bestRFN = 10\n",
    "bestRFS = 2\n",
    "\n",
    "for n in [50]:\n",
    "    for s in [12]:\n",
    "        RF = RandomForestRegressor(n_estimators=n, min_samples_split=s)\n",
    "        RF.fit(X_tmp_train, Y_tmp_train)\n",
    "        rmse = np.sqrt(np.mean((RF.predict(X_tmp_validate) - Y_tmp_validate) ** 2))\n",
    "        print(\"Validation RMSE for n = %d, min_samples_split = %d: %.4f\" % (n, s, rmse))\n",
    "        if (rmse < bestRFValidateRMSE):\n",
    "            bestRFValidateRMSE = rmse\n",
    "            bestRFN = n\n",
    "            bestRFS = s\n",
    "\n",
    "print \"The best N for RF was: %d, with min_samples_split: %d, with RMSE: %.4f\" % (bestRFN, bestRFS, bestRFValidateRMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Data\n",
    "\n",
    "Once all feature engineering and model tuning has been completed, test the data on the withheld test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST RF N: 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e30d10001cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"BEST RF N: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbestRFN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mRF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestRFN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbestRFS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tmp_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_tmp_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test RMSE: %.4f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tmp_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_tmp_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    660\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test the final settings for the Random Forest Regressor\n",
    "print \"BEST RF N: %d\" % bestRFN\n",
    "RF = RandomForestRegressor(n_estimators=bestRFN, min_samples_split=bestRFS)\n",
    "RF.fit(X_tmp_train, Y_tmp_train)\n",
    "print(\"Test RMSE: %.4f\" % np.sqrt(np.mean((RF.predict(X_tmp_test) - Y_tmp_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Creation\n",
    "\n",
    "Create the prediction.csv to upload to Kaggle.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the Random Forest on the full X_train set \n",
    "RF = RandomForestRegressor(n_estimators=50, min_samples_split=12)\n",
    "RF.fit(X_train, Y_train)\n",
    "RF_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"prediction.csv\", RF_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
