{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Here we import that data from the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countChars(df):\n",
    "    chardict = {}\n",
    "    \n",
    "    smiles = df.smiles\n",
    "    smileydict = dict(Counter(''.join(smiles)))\n",
    "    print smileydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1780083, 'H': 1044808, 'S': 440512, '[': 1418750, ']': 1418750, 'c': 19806746, 'e': 363405, ')': 1760336, '(': 1760336, '-': 1405646, 's': 1948507, 'o': 591266, 'n': 2182474, '1': 4165508, 'i': 440512, '3': 2621702, '2': 4332412, '5': 560778, '4': 1566686, '6': 131512, '=': 916664}\n"
     ]
    }
   ],
   "source": [
    "countChars(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Here we extract features from the SMILES string and winnow down the existing features to create a more robust feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatures(df):\n",
    "\n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        \n",
    "    \n",
    "    ###########################\n",
    "    ### FEATURE ENGINEERING ###\n",
    "    ###########################\n",
    "    #smiles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "    #df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "    # Add length of smile\n",
    "    df['smile_length'] = df.smiles.map(lambda x: len(x))\n",
    "\n",
    "    # Add number of C's divided by length\n",
    "    df['smile_percentc'] = (df.smile_c / df.smile_length)\n",
    "    df['smile_percentC'] = (df.smile_C / df.smile_length)\n",
    "\n",
    "    # Count specific molecules\n",
    "    # [nH]\n",
    "    df['smile_nh'] = df.smiles.map(lambda x: '[nH]' in x)\n",
    "    df['smile_si'] = df.smiles.map(lambda x: 'Si' in x)\n",
    "    df['smile_sih2'] = df.smiles.map(lambda x: '[SiH2]' in x)\n",
    "    df['smile_se'] = df.smiles.map(lambda x: '[se]' in x)\n",
    "    df['smile_CdoubleC'] = df.smiles.map(lambda x: 'C=C' in x)\n",
    "    df['smile_doubleC'] = df.smiles.map(lambda x: 'CC' in x)\n",
    "    df['smile_doublec'] = df.smiles.map(lambda x: 'cc' in x)\n",
    "    df['smile_triplec'] = df.smiles.map(lambda x: 'ccc' in x)\n",
    "    df['smile_quadc'] = df.smiles.map(lambda x: 'cccc' in x)\n",
    "    df['smile_quintc'] = df.smiles.map(lambda x: 'ccccc' in x)\n",
    "    #df['smile_c2'] = df.smiles.map(lambda x: 'c2' in x)\n",
    "    #df['smile_c3'] = df.smiles.map(lambda x: 'c3' in x)\n",
    "    #df['smile_c4'] = df.smiles.map(lambda x: 'c4' in x)\n",
    "\n",
    "    df['smile_C1equalCc2'] = df.smiles.map(lambda x: 'C1=Cc2' in x)\n",
    "    df['smile_C1'] = df.smiles.map(lambda x: 'C1' in x)\n",
    "    df['smile_c1'] = df.smiles.map(lambda x: 'c1' in x)\n",
    "    df['smile_equalCCCequal'] = df.smiles.map(lambda x: '=CCC=' in x)\n",
    "    df['smile_equalCCequal'] = df.smiles.map(lambda x: '=CC=' in x)\n",
    "    df['smile_equalCequal'] = df.smiles.map(lambda x: '=C=' in x)\n",
    "    df['smile_C1equalCCequalC'] = df.smiles.map(lambda x: 'C1=CC=C' in x)\n",
    "\n",
    "    # Parentheses molecules\n",
    "    df['smile_parenC1'] = df.smiles.map(lambda x: '(C1)' in x)\n",
    "    df['smile_parenc1'] = df.smiles.map(lambda x: '(c1)' in x)\n",
    "    df['smile_parencc1'] = df.smiles.map(lambda x: '(cc1)' in x)\n",
    "    df['smile_pareno1'] = df.smiles.map(lambda x: '(o1)' in x)\n",
    "    df['smile_parens1'] = df.smiles.map(lambda x: '(s1)' in x)\n",
    "    df['smile_parenccc4mol'] = df.smiles.map(lambda x: '(ccc4=C[SiH2]C=c34)' in x)\n",
    "    df['smile_parenccinnermol'] = df.smiles.map(lambda x: '(cc(-c3ccco3)c3=CCC=c13)' in x)\n",
    "    df['smile_parennegc3cco3'] = df.smiles.map(lambda x: '(-c3ccco3)' in x)\n",
    "    df['smile_parenncc3c12'] = df.smiles.map(lambda x: '(ncc3c12)' in x)\n",
    "    df['smile_parenccc34'] = df.smiles.map(lambda x: '(ccc34)' in x)\n",
    "    df['smile_parencc4ccc3c2cn1'] = df.smiles.map(lambda x: '(cc4ccc3c2cn1)' in x)\n",
    "\n",
    "    # Special\n",
    "    df['smile_percent_aromatic'] = (df.smile_c + df.smile_o + df.smile_n + df.smile_s / df.smile_length)\n",
    "\n",
    "    # Start\n",
    "    df['smile_start_C1'] = df.smiles.map(lambda x: x.startswith('C1'))\n",
    "    df['smile_start_C1equal'] = df.smiles.map(lambda x: x.startswith('C1='))\n",
    "    df['smile_start_c1'] = df.smiles.map(lambda x: x.startswith('c1'))\n",
    "    df['smile_start_cc1'] = df.smiles.map(lambda x: x.startswith('cc1'))\n",
    "    df['smile_start_c1sc'] = df.smiles.map(lambda x: x.startswith('c1sc'))\n",
    "    df['smile_start_c1ccc'] = df.smiles.map(lambda x: x.startswith('c1ccc'))\n",
    "    df['smile_start_nH'] = df.smiles.map(lambda x: x.startswith('[nH]'))\n",
    "    df['smile_start_C1equalCCequalC'] = df.smiles.map(lambda x: x.startswith('C1=CC=C'))\n",
    "\n",
    "    # End\n",
    "    df['smile_end_c1ccc'] = df.smiles.map(lambda x: x.endswith('c1ccc'))\n",
    "    df['smile_end_o1'] = df.smiles.map(lambda x: x.endswith('o1'))\n",
    "    df['smile_end_ccsc12'] = df.smiles.map(lambda x: x.endswith('ccsc12'))\n",
    "\n",
    "    #df['smile_percent_bond'] = df.smile_equal / df.smile_length\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    ### DROP UNNECESSARY COLUMNS ###\n",
    "    #############################    \n",
    "    df = df.drop('smile_length', axis=1)\n",
    "    df = df.drop(['smiles'], axis=1)\n",
    "    \n",
    "    \n",
    "    # Return the data frame with all of the new features added in\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 52)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 52)\n"
     ]
    }
   ],
   "source": [
    "# Clean up Actual Training and Testing Data\n",
    "X_train = makeFeatures(df_train)\n",
    "\n",
    "# Delete 'gap' column in training\n",
    "X_train = X_train.drop(['gap'], axis=1)\n",
    "\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (640000, 52)\n",
      "Y Training Shape (640000,)\n",
      "Validation Shape (160000, 52)\n",
      "Y Validation Shape (160000,)\n",
      "Test Shape (200000, 52)\n",
      "Y Test Shape (200000,)\n"
     ]
    }
   ],
   "source": [
    "# Take a sample of the full training data set for training and validation sets\n",
    "# Create the temporary training and validation combined sets\n",
    "# Create the testing sample\n",
    "X_tmp_trainvalidate, X_tmp_test, Y_tmp_trainvalidate, Y_tmp_test = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n",
    "X_tmp_train, X_tmp_validate, Y_tmp_train, Y_tmp_validate = train_test_split(X_tmp_trainvalidate, Y_tmp_trainvalidate, test_size=0.20, random_state=42)\n",
    "\n",
    "print \"Training Shape\", X_tmp_train.shape\n",
    "print \"Y Training Shape\", Y_tmp_train.shape\n",
    "print \"Validation Shape\", X_tmp_validate.shape\n",
    "print \"Y Validation Shape\", Y_tmp_validate.shape\n",
    "print \"Test Shape\", X_tmp_test.shape\n",
    "print \"Y Test Shape\", Y_tmp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Here we test out a series of models on the training and validation sets to determine which is the optimum one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Sample Linear Regression Testing\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "LR.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "# RMSE\n",
    "rms = sqrt(mean_squared_error(Y_tmp_validate, LR.predict(X_tmp_validate)))\n",
    "print(\"RMSE: %.3f\" % rms)\n",
    "#print(\"RMSE: %.3f\" % np.sqrt(np.mean((LR.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.3f' % LR.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TOO SLOW!\n",
    "# Sample Polynomial Interpolation Testing\n",
    "#Poly = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "#Poly.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "#print \"RMSE: %.3f\" % np.sqrt(np.mean((Poly.predict(X_tmp_validate) - Y_tmp_validate) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Sample Ridge Testing\n",
    "Ridge = linear_model.Ridge()\n",
    "\n",
    "Ridge.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Ridge.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Ridge.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.233\n",
      "Variance score: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Sample Lasso Testing\n",
    "Lasso = linear_model.Lasso(alpha=.01, selection='random')\n",
    "\n",
    "Lasso.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Lasso.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Lasso.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DO NOT RUN - TOO SLOW\n",
    "# # KNN\n",
    "# KNN = neighbors.KNeighborsRegressor(n_neighbors=12)\n",
    "\n",
    "# KNN.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "# #print \"N_neighbors: %d\" % 12\n",
    "# print(\"RMSE: %.3f\" % np.sqrt(np.mean((KNN.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "# print('Variance score: %.3f' % KNN.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.123\n",
      "Variance score: 0.908\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Testing\n",
    "RF = RandomForestRegressor(n_estimators=30, min_samples_split=8)\n",
    "\n",
    "RF.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % RF.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building an Ensemble\n",
    "lr_predictions = LR.predict(X_tmp_train)\n",
    "ridge_predictions = Ridge.predict(X_tmp_train)\n",
    "lasso_predictions = Lasso.predict(X_tmp_train)\n",
    "#knn_predictions = KNN.predict(X_tmp_train)\n",
    "rf_predictions = RF.predict(X_tmp_train)\n",
    "\n",
    "\n",
    "dfensemble=pd.DataFrame.from_dict({'lr':lr_predictions,\n",
    "                                   'ridge':ridge_predictions,\n",
    "                                   'lasso':lasso_predictions, \n",
    "                                   #'knn':knn_predictions,\n",
    "                                   'rf':rf_predictions,\n",
    "                                   'y':Y_tmp_train})\n",
    "\n",
    "est = LinearRegression()\n",
    "#est.fit(dfensemble[['lr', 'ridge', 'lasso', 'knn', 'rf']].values, dfensemble['y'])\n",
    "est.fit(dfensemble[['lr', 'ridge', 'lasso', 'rf']].values, dfensemble['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "RMSE: 0.124\n"
     ]
    }
   ],
   "source": [
    "# Validating the Ensemble\n",
    "lr_predictions_test = LR.predict(X_tmp_validate)\n",
    "ridge_predictions_test = Ridge.predict(X_tmp_validate)\n",
    "lasso_predictions_test = Lasso.predict(X_tmp_validate)\n",
    "#knn_predictions_test = KNN.predict(X_tmp_validate)\n",
    "rf_predictions_test = RF.predict(X_tmp_validate)\n",
    "\n",
    "dfensemblevalidate=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   #'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test})\n",
    "\n",
    "#epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "epredsvalidate = est.predict(dfensemblevalidate[['lr', 'ridge', 'lasso', 'rf']].values)\n",
    "\n",
    "print \"Validation Set\"\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epredsvalidate - Y_tmp_validate) ** 2)))\n",
    "#print('Variance score: %.3f' % est.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set\n",
      "RMSE: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Testing the Ensemble\n",
    "lr_predictions_test = LR.predict(X_tmp_test)\n",
    "ridge_predictions_test = Ridge.predict(X_tmp_test)\n",
    "lasso_predictions_test = Lasso.predict(X_tmp_test)\n",
    "#knn_predictions_test = KNN.predict(X_tmp_test)\n",
    "rf_predictions_test = RF.predict(X_tmp_test)\n",
    "\n",
    "dfensembletest=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   #'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test})\n",
    "\n",
    "#epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "epredstest = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'rf']].values)\n",
    "\n",
    "print \"Test Set\"\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epredstest - Y_tmp_test) ** 2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
