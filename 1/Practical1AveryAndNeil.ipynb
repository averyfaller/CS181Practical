{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Here we import that data from the CSV files and create a subset sample to do rapid training and validation cycles on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Here we extract features from the SMILES string and winnow down the existing features to create a more robust feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatures(df):\n",
    "    \n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        \n",
    "    \n",
    "    ###########################\n",
    "    ### FEATURE ENGINEERING ###\n",
    "    ###########################\n",
    "    #smiles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "    #df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "    # Add length of smile\n",
    "    df['smile_length'] = df.smiles.map(lambda x: len(x))\n",
    "\n",
    "    # Add number of C's divided by length\n",
    "    df['smile_percentc'] = (df.smile_c / df.smile_length)\n",
    "    df['smile_percentC'] = (df.smile_C / df.smile_length)\n",
    "\n",
    "    # Count specific molecules\n",
    "    # [nH]\n",
    "    df['smile_nh'] = df.smiles.map(lambda x: x.count('[nH]'))\n",
    "    df['smile_si'] = df.smiles.map(lambda x: x.count('Si'))\n",
    "    df['smile_sih2'] = df.smiles.map(lambda x: x.count('[SiH2]'))\n",
    "    df['smile_se'] = df.smiles.map(lambda x: x.count('[se]'))\n",
    "    df['smile_CdoubleC'] = df.smiles.map(lambda x: x.count('C=C'))\n",
    "    df['smile_doubleC'] = df.smiles.map(lambda x: x.count('CC'))\n",
    "    df['smile_doublec'] = df.smiles.map(lambda x: x.count('cc'))\n",
    "    df['smile_triplec'] = df.smiles.map(lambda x: x.count('ccc'))\n",
    "    df['smile_quadc'] = df.smiles.map(lambda x: x.count('cccc'))\n",
    "    df['smile_quintc'] = df.smiles.map(lambda x: x.count('ccccc'))\n",
    "    #df['smile_c2'] = df.smiles.map(lambda x: x.count('c2'))\n",
    "    #df['smile_c3'] = df.smiles.map(lambda x: x.count('c3'))\n",
    "    #df['smile_c4'] = df.smiles.map(lambda x: x.count('c4'))\n",
    "\n",
    "    df['smile_C1equalCc2'] = df.smiles.map(lambda x: x.count('C1=Cc2'))\n",
    "    df['smile_C1'] = df.smiles.map(lambda x: x.count('C1'))\n",
    "    df['smile_c1'] = df.smiles.map(lambda x: x.count('c1'))\n",
    "    df['smile_equalCCCequal'] = df.smiles.map(lambda x: x.count('=CCC='))\n",
    "    df['smile_equalCCequal'] = df.smiles.map(lambda x: x.count('=CC='))\n",
    "    df['smile_equalCequal'] = df.smiles.map(lambda x: x.count('=C='))\n",
    "    df['smile_C1equalCCequalC'] = df.smiles.map(lambda x: x.count('C1=CC=C'))\n",
    "\n",
    "    # Parentheses molecules\n",
    "    df['smile_parenC1'] = df.smiles.map(lambda x: x.count('(C1)'))\n",
    "    df['smile_parenc1'] = df.smiles.map(lambda x: x.count('(c1)'))\n",
    "    df['smile_parencc1'] = df.smiles.map(lambda x: x.count('(cc1)'))\n",
    "    df['smile_pareno1'] = df.smiles.map(lambda x: x.count('(o1)'))\n",
    "    df['smile_parens1'] = df.smiles.map(lambda x: x.count('(s1)'))\n",
    "    df['smile_parenccc4mol'] = df.smiles.map(lambda x: x.count('(ccc4=C[SiH2]C=c34)'))\n",
    "    df['smile_parenccinnermol'] = df.smiles.map(lambda x: x.count('(cc(-c3ccco3)c3=CCC=c13)'))\n",
    "    df['smile_parennegc3cco3'] = df.smiles.map(lambda x: x.count('(-c3ccco3)'))\n",
    "    df['smile_parenncc3c12'] = df.smiles.map(lambda x: x.count('(ncc3c12)'))\n",
    "    df['smile_parenccc34'] = df.smiles.map(lambda x: x.count('(ccc34)'))\n",
    "    df['smile_parencc4ccc3c2cn1'] = df.smiles.map(lambda x: x.count('(cc4ccc3c2cn1)'))\n",
    "\n",
    "    # Special\n",
    "    df['smile_percent_aromatic'] = (df.smile_c + df.smile_o + df.smile_n + df.smile_s / df.smile_length)\n",
    "\n",
    "    # Start\n",
    "    df['smile_start_C1'] = df.smiles.map(lambda x: x.startswith('C1'))\n",
    "    df['smile_start_C1equal'] = df.smiles.map(lambda x: x.startswith('C1='))\n",
    "    df['smile_start_c1'] = df.smiles.map(lambda x: x.startswith('c1'))\n",
    "    df['smile_start_cc1'] = df.smiles.map(lambda x: x.startswith('cc1'))\n",
    "    df['smile_start_c1sc'] = df.smiles.map(lambda x: x.startswith('c1sc'))\n",
    "    df['smile_start_c1ccc'] = df.smiles.map(lambda x: x.startswith('c1ccc'))\n",
    "    df['smile_start_nH'] = df.smiles.map(lambda x: x.startswith('[nH]'))\n",
    "    df['smile_start_C1equalCCequalC'] = df.smiles.map(lambda x: x.startswith('C1=CC=C'))\n",
    "\n",
    "    # End\n",
    "    df['smile_end_c1ccc'] = df.smiles.map(lambda x: x.endswith('c1ccc'))\n",
    "    df['smile_end_o1'] = df.smiles.map(lambda x: x.endswith('o1'))\n",
    "    df['smile_end_ccsc12'] = df.smiles.map(lambda x: x.endswith('ccsc12'))\n",
    "\n",
    "    #df['smile_percent_bond'] = df.smile_equal / df.smile_length\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ### DROP UNNECESSARY COLUMNS ###\n",
    "    ################################    \n",
    "    df = df.drop('smile_length', axis=1)\n",
    "    df = df.drop(['smiles'], axis=1)\n",
    "    \n",
    "    \n",
    "    # Return the data frame with all of the new features added in\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 94)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 94)\n"
     ]
    }
   ],
   "source": [
    "# Clean up Actual Training and Testing Data\n",
    "X_train = makeFeatures(df_train)\n",
    "X_test = makeFeatures(df_test)\n",
    "\n",
    "# Delete 'gap' column in training\n",
    "X_train = X_train.drop(['gap'], axis=1)\n",
    "\n",
    "# Delete 'Id' column in testing\n",
    "X_test = X_test.drop(['Id'], axis=1)\n",
    "\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (640000, 94)\n",
      "Y Training Shape (640000,)\n",
      "Validation Shape (160000, 94)\n",
      "Y Validation Shape (160000,)\n",
      "Test Shape (200000, 94)\n",
      "Y Test Shape (200000,)\n"
     ]
    }
   ],
   "source": [
    "# Take a sample of the full training data set for training and validation sets\n",
    "# Create the temporary training and validation combined sets\n",
    "# Create the testing sample\n",
    "X_tmp_trainvalidate, X_tmp_test, Y_tmp_trainvalidate, Y_tmp_test = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n",
    "X_tmp_train, X_tmp_validate, Y_tmp_train, Y_tmp_validate = train_test_split(X_tmp_trainvalidate, Y_tmp_trainvalidate, test_size=0.20, random_state=42)\n",
    "\n",
    "print \"Training Shape\", X_tmp_train.shape\n",
    "print \"Y Training Shape\", Y_tmp_train.shape\n",
    "print \"Validation Shape\", X_tmp_validate.shape\n",
    "print \"Y Validation Shape\", Y_tmp_validate.shape\n",
    "print \"Test Shape\", X_tmp_test.shape\n",
    "print \"Y Test Shape\", Y_tmp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Here we test out a series of models on the training and validation sets to determine which is the optimum one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.740\n"
     ]
    }
   ],
   "source": [
    "# Sample Linear Regression Testing\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "LR.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "# The coefficients\n",
    "#print('Coefficients: \\n', LR.coef_)\n",
    "# RMSE\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((LR.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.3f' % LR.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TOO SLOW!\n",
    "# Sample Polynomial Interpolation Testing\n",
    "#Poly = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "#Poly.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "#print \"RMSE: %.3f\" % np.sqrt(np.mean((Poly.predict(X_tmp_validate) - Y_tmp_validate) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.740\n"
     ]
    }
   ],
   "source": [
    "# Sample Ridge Testing\n",
    "Ridge = linear_model.Ridge(alpha = .001)\n",
    "\n",
    "Ridge.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Ridge.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Ridge.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.212\n",
      "Variance score: 0.728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Sample Lasso Testing\n",
    "Lasso = linear_model.Lasso(alpha = .001)\n",
    "\n",
    "Lasso.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Lasso.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Lasso.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.186\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "KNN = neighbors.KNeighborsRegressor(n_neighbors=12)\n",
    "\n",
    "KNN.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "#print \"N_neighbors: %d\" % 12\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((KNN.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % KNN.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.117\n",
      "Variance score: 0.917\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Testing\n",
    "RF = RandomForestRegressor(n_estimators=30, min_samples_split=8)\n",
    "\n",
    "# Try with pwoer bases\n",
    "#from numpy import *\n",
    "#tmp_in = np.hstack((X_tmp_train, X_tmp_train**2))\n",
    "#tmp_in_validate = np.hstack((X_tmp_validate, X_tmp_validate**2))\n",
    "\n",
    "#RF.fit(tmp_in, Y_tmp_train)\n",
    "#print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(tmp_in_validate) - Y_tmp_validate) ** 2)))\n",
    "\n",
    "\n",
    "RF.fit(X_tmp_train, Y_tmp_train)\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % RF.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.118\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(X_tmp_test) - Y_tmp_test) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building an Ensemble\n",
    "lr_predictions = LR.predict(df_sample_train)\n",
    "ridge_predictions = Ridge.predict(df_sample_train)\n",
    "lasso_predictions = Lasso.predict(df_sample_train)\n",
    "knn_predictions = KNN.predict(df_sample_train)\n",
    "rf_predictions = RF.predict(df_sample_train)\n",
    "\n",
    "\n",
    "dfensemble=pd.DataFrame.from_dict({'lr':lr_predictions,\n",
    "                                   'ridge':ridge_predictions,\n",
    "                                   'lasso':lasso_predictions, \n",
    "                                   'knn':knn_predictions,\n",
    "                                   'rf':rf_predictions,\n",
    "                                   'y':Y_sample_train})\n",
    "\n",
    "est = LinearRegression()\n",
    "est.fit(dfensemble[['lr', 'ridge', 'lasso', 'knn', 'rf']].values, dfensemble['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.156\n"
     ]
    }
   ],
   "source": [
    "# Testing the Ensemble\n",
    "lr_predictions_test = LR.predict(df_sample_test)\n",
    "ridge_predictions_test = Ridge.predict(df_sample_test)\n",
    "lasso_predictions_test = Lasso.predict(df_sample_test)\n",
    "knn_predictions_test = KNN.predict(df_sample_test)\n",
    "rf_predictions_test = RF.predict(df_sample_test)\n",
    "\n",
    "dfensembletest=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test,\n",
    "                                   'y':Y_sample_test})\n",
    "\n",
    "epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epreds - Y_sample_test) ** 2)))\n",
    "#print('Variance score: %.3f' % est.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Now that we have discovered the best model and features, we run our model fitting on the full training data set.  Then we use that to predict the scores of our test data set and export the predictions to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest Prediction\n",
    "RF = RandomForestRegressor(n_estimators=10, min_samples_split=8)\n",
    "\n",
    "# Try Basis functions\n",
    "tmp_train = np.hstack((X_train, X_train**2))\n",
    "tmp_test = np.hstack((X_test, X_test**2))\n",
    "RF.fit(tmp_train, Y_train)\n",
    "prediction = RF.predict(tmp_test)\n",
    "\n",
    "#RF.fit(X_train, Y_train)\n",
    "#prediction = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sample Linear Regression Testing\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, Y_train)\n",
    "prediction = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"prediction.csv\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
