{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from numpy import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Here we import that data from the CSV files and create a subset sample to do rapid training and validation cycles on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Store gap values\n",
    "Y_train = df_train.gap.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def countChars(df):\n",
    "    chardict = {}\n",
    "    \n",
    "    smiles = df.smiles\n",
    "    smileydict = dict(Counter(''.join(smiles)))\n",
    "    print smileydict\n",
    "    #smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    #for smile in smile_alphabet:\n",
    "    #    smilechar = smile\n",
    "    #    if smile == '=':\n",
    "    #        smilechar = 'equal'\n",
    "    #    df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1780083, 'H': 1044808, 'S': 440512, '[': 1418750, ']': 1418750, 'c': 19806746, 'e': 363405, ')': 1760336, '(': 1760336, '-': 1405646, 's': 1948507, 'o': 591266, 'n': 2182474, '1': 4165508, 'i': 440512, '3': 2621702, '2': 4332412, '5': 560778, '4': 1566686, '6': 131512, '=': 916664}\n"
     ]
    }
   ],
   "source": [
    "countChars(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatures(df):\n",
    "    \n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        \n",
    "    df = df.drop(['smiles'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Here we extract features from the SMILES string and winnow down the existing features to create a more robust feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatures(df):\n",
    "\n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        \n",
    "    \n",
    "    ###########################\n",
    "    ### FEATURE ENGINEERING ###\n",
    "    ###########################\n",
    "    #smiles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "    #df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "    # Add length of smile\n",
    "    df['smile_length'] = df.smiles.map(lambda x: len(x))\n",
    "\n",
    "    # Add number of C's divided by length\n",
    "    df['smile_percentc'] = (df.smile_c / df.smile_length)\n",
    "    df['smile_percentC'] = (df.smile_C / df.smile_length)\n",
    "\n",
    "    # Count specific molecules\n",
    "    # [nH]\n",
    "    df['smile_nh'] = df.smiles.map(lambda x: '[nH]' in x)\n",
    "    df['smile_si'] = df.smiles.map(lambda x: 'Si' in x)\n",
    "    df['smile_sih2'] = df.smiles.map(lambda x: '[SiH2]' in x)\n",
    "    df['smile_se'] = df.smiles.map(lambda x: '[se]' in x)\n",
    "    df['smile_CdoubleC'] = df.smiles.map(lambda x: 'C=C' in x)\n",
    "    df['smile_doubleC'] = df.smiles.map(lambda x: 'CC' in x)\n",
    "    df['smile_doublec'] = df.smiles.map(lambda x: 'cc' in x)\n",
    "    df['smile_triplec'] = df.smiles.map(lambda x: 'ccc' in x)\n",
    "    df['smile_quadc'] = df.smiles.map(lambda x: 'cccc' in x)\n",
    "    df['smile_quintc'] = df.smiles.map(lambda x: 'ccccc' in x)\n",
    "    #df['smile_c2'] = df.smiles.map(lambda x: 'c2' in x)\n",
    "    #df['smile_c3'] = df.smiles.map(lambda x: 'c3' in x)\n",
    "    #df['smile_c4'] = df.smiles.map(lambda x: 'c4' in x)\n",
    "\n",
    "    df['smile_C1equalCc2'] = df.smiles.map(lambda x: 'C1=Cc2' in x)\n",
    "    df['smile_C1'] = df.smiles.map(lambda x: 'C1' in x)\n",
    "    df['smile_c1'] = df.smiles.map(lambda x: 'c1' in x)\n",
    "    df['smile_equalCCCequal'] = df.smiles.map(lambda x: '=CCC=' in x)\n",
    "    df['smile_equalCCequal'] = df.smiles.map(lambda x: '=CC=' in x)\n",
    "    df['smile_equalCequal'] = df.smiles.map(lambda x: '=C=' in x)\n",
    "    df['smile_C1equalCCequalC'] = df.smiles.map(lambda x: 'C1=CC=C' in x)\n",
    "\n",
    "    # Parentheses molecules\n",
    "    df['smile_parenC1'] = df.smiles.map(lambda x: '(C1)' in x)\n",
    "    df['smile_parenc1'] = df.smiles.map(lambda x: '(c1)' in x)\n",
    "    df['smile_parencc1'] = df.smiles.map(lambda x: '(cc1)' in x)\n",
    "    df['smile_pareno1'] = df.smiles.map(lambda x: '(o1)' in x)\n",
    "    df['smile_parens1'] = df.smiles.map(lambda x: '(s1)' in x)\n",
    "    df['smile_parenccc4mol'] = df.smiles.map(lambda x: '(ccc4=C[SiH2]C=c34)' in x)\n",
    "    df['smile_parenccinnermol'] = df.smiles.map(lambda x: '(cc(-c3ccco3)c3=CCC=c13)' in x)\n",
    "    df['smile_parennegc3cco3'] = df.smiles.map(lambda x: '(-c3ccco3)' in x)\n",
    "    df['smile_parenncc3c12'] = df.smiles.map(lambda x: '(ncc3c12)' in x)\n",
    "    df['smile_parenccc34'] = df.smiles.map(lambda x: '(ccc34)' in x)\n",
    "    df['smile_parencc4ccc3c2cn1'] = df.smiles.map(lambda x: '(cc4ccc3c2cn1)' in x)\n",
    "\n",
    "    # Special\n",
    "    df['smile_percent_aromatic'] = (df.smile_c + df.smile_o + df.smile_n + df.smile_s / df.smile_length)\n",
    "\n",
    "    # Start\n",
    "    df['smile_start_C1'] = df.smiles.map(lambda x: x.startswith('C1'))\n",
    "    df['smile_start_C1equal'] = df.smiles.map(lambda x: x.startswith('C1='))\n",
    "    df['smile_start_c1'] = df.smiles.map(lambda x: x.startswith('c1'))\n",
    "    df['smile_start_cc1'] = df.smiles.map(lambda x: x.startswith('cc1'))\n",
    "    df['smile_start_c1sc'] = df.smiles.map(lambda x: x.startswith('c1sc'))\n",
    "    df['smile_start_c1ccc'] = df.smiles.map(lambda x: x.startswith('c1ccc'))\n",
    "    df['smile_start_nH'] = df.smiles.map(lambda x: x.startswith('[nH]'))\n",
    "    df['smile_start_C1equalCCequalC'] = df.smiles.map(lambda x: x.startswith('C1=CC=C'))\n",
    "\n",
    "    # End\n",
    "    df['smile_end_c1ccc'] = df.smiles.map(lambda x: x.endswith('c1ccc'))\n",
    "    df['smile_end_o1'] = df.smiles.map(lambda x: x.endswith('o1'))\n",
    "    df['smile_end_ccsc12'] = df.smiles.map(lambda x: x.endswith('ccsc12'))\n",
    "\n",
    "    #df['smile_percent_bond'] = df.smile_equal / df.smile_length\n",
    "    \n",
    "    \n",
    "    #############################\n",
    "    ### DROP UNNECESSARY COLUMNS ###\n",
    "    #############################    \n",
    "    df = df.drop('smile_length', axis=1)\n",
    "    df = df.drop(['smiles'], axis=1)\n",
    "    \n",
    "    \n",
    "    # Return the data frame with all of the new features added in\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1000000, 52)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 52)\n"
     ]
    }
   ],
   "source": [
    "# Clean up Actual Training and Testing Data\n",
    "X_train = makeFeatures(df_train)\n",
    "X_test = makeFeatures(df_test)\n",
    "\n",
    "# Delete 'gap' column in training\n",
    "X_train = X_train.drop(['gap'], axis=1)\n",
    "\n",
    "# Delete 'Id' column in testing\n",
    "X_test = X_test.drop(['Id'], axis=1)\n",
    "\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (640000, 52)\n",
      "Y Training Shape (640000,)\n",
      "Validation Shape (160000, 52)\n",
      "Y Validation Shape (160000,)\n",
      "Test Shape (200000, 52)\n",
      "Y Test Shape (200000,)\n"
     ]
    }
   ],
   "source": [
    "# Take a sample of the full training data set for training and validation sets\n",
    "# Create the temporary training and validation combined sets\n",
    "# Create the testing sample\n",
    "X_tmp_trainvalidate, X_tmp_test, Y_tmp_trainvalidate, Y_tmp_test = train_test_split(X_train, Y_train, test_size=0.20, random_state=42)\n",
    "X_tmp_train, X_tmp_validate, Y_tmp_train, Y_tmp_validate = train_test_split(X_tmp_trainvalidate, Y_tmp_trainvalidate, test_size=0.20, random_state=42)\n",
    "\n",
    "print \"Training Shape\", X_tmp_train.shape\n",
    "print \"Y Training Shape\", Y_tmp_train.shape\n",
    "print \"Validation Shape\", X_tmp_validate.shape\n",
    "print \"Y Validation Shape\", Y_tmp_validate.shape\n",
    "print \"Test Shape\", X_tmp_test.shape\n",
    "print \"Y Test Shape\", Y_tmp_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Here we test out a series of models on the training and validation sets to determine which is the optimum one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Sample Linear Regression Testing\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "LR.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "# RMSE\n",
    "rms = sqrt(mean_squared_error(Y_tmp_validate, LR.predict(X_tmp_validate)))\n",
    "print(\"RMSE: %.3f\" % rms)\n",
    "#print(\"RMSE: %.3f\" % np.sqrt(np.mean((LR.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.3f' % LR.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TOO SLOW!\n",
    "# Sample Polynomial Interpolation Testing\n",
    "#Poly = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "#Poly.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "#print \"RMSE: %.3f\" % np.sqrt(np.mean((Poly.predict(X_tmp_validate) - Y_tmp_validate) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.208\n",
      "Variance score: 0.738\n"
     ]
    }
   ],
   "source": [
    "# Sample Ridge Testing\n",
    "Ridge = linear_model.Ridge()\n",
    "\n",
    "Ridge.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Ridge.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Ridge.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.233\n",
      "Variance score: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Sample Lasso Testing\n",
    "Lasso = linear_model.Lasso(alpha=.01, selection='random')\n",
    "\n",
    "Lasso.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Lasso.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % Lasso.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DO NOT RUN - TOO SLOW\n",
    "# # KNN\n",
    "# KNN = neighbors.KNeighborsRegressor(n_neighbors=12)\n",
    "\n",
    "# KNN.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "# #print \"N_neighbors: %d\" % 12\n",
    "# print(\"RMSE: %.3f\" % np.sqrt(np.mean((KNN.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "# print('Variance score: %.3f' % KNN.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.123\n",
      "Variance score: 0.908\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Testing\n",
    "RF = RandomForestRegressor(n_estimators=30, min_samples_split=8)\n",
    "\n",
    "RF.fit(X_tmp_train, Y_tmp_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(X_tmp_validate) - Y_tmp_validate) ** 2)))\n",
    "print('Variance score: %.3f' % RF.score(X_tmp_validate, Y_tmp_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building an Ensemble\n",
    "lr_predictions = LR.predict(X_tmp_train)\n",
    "ridge_predictions = Ridge.predict(X_tmp_train)\n",
    "lasso_predictions = Lasso.predict(X_tmp_train)\n",
    "#knn_predictions = KNN.predict(X_tmp_train)\n",
    "rf_predictions = RF.predict(X_tmp_train)\n",
    "\n",
    "\n",
    "dfensemble=pd.DataFrame.from_dict({'lr':lr_predictions,\n",
    "                                   'ridge':ridge_predictions,\n",
    "                                   'lasso':lasso_predictions, \n",
    "                                   #'knn':knn_predictions,\n",
    "                                   'rf':rf_predictions,\n",
    "                                   'y':Y_tmp_train})\n",
    "\n",
    "est = LinearRegression()\n",
    "#est.fit(dfensemble[['lr', 'ridge', 'lasso', 'knn', 'rf']].values, dfensemble['y'])\n",
    "est.fit(dfensemble[['lr', 'ridge', 'lasso', 'rf']].values, dfensemble['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set\n",
      "RMSE: 0.124\n"
     ]
    }
   ],
   "source": [
    "# Validating the Ensemble\n",
    "lr_predictions_test = LR.predict(X_tmp_validate)\n",
    "ridge_predictions_test = Ridge.predict(X_tmp_validate)\n",
    "lasso_predictions_test = Lasso.predict(X_tmp_validate)\n",
    "#knn_predictions_test = KNN.predict(X_tmp_validate)\n",
    "rf_predictions_test = RF.predict(X_tmp_validate)\n",
    "\n",
    "dfensemblevalidate=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   #'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test})\n",
    "\n",
    "#epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "epredsvalidate = est.predict(dfensemblevalidate[['lr', 'ridge', 'lasso', 'rf']].values)\n",
    "\n",
    "print \"Validation Set\"\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epredsvalidate - Y_tmp_validate) ** 2)))\n",
    "#print('Variance score: %.3f' % est.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set\n",
      "RMSE: 0.125\n"
     ]
    }
   ],
   "source": [
    "# Testing the Ensemble\n",
    "lr_predictions_test = LR.predict(X_tmp_test)\n",
    "ridge_predictions_test = Ridge.predict(X_tmp_test)\n",
    "lasso_predictions_test = Lasso.predict(X_tmp_test)\n",
    "#knn_predictions_test = KNN.predict(X_tmp_test)\n",
    "rf_predictions_test = RF.predict(X_tmp_test)\n",
    "\n",
    "dfensembletest=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   #'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test})\n",
    "\n",
    "#epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "epredstest = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'rf']].values)\n",
    "\n",
    "print \"Test Set\"\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epredstest - Y_tmp_test) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "Now that we have discovered the best model and features, we run our model fitting on the full training data set.  Then we use that to predict the scores of our test data set and export the predictions to a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Random Forest Prediction\n",
    "# RF = RandomForestRegressor(n_estimators=10, min_samples_split=8)\n",
    "\n",
    "# # Try Basis functions\n",
    "# tmp_train = np.hstack((X_train, X_train**2))\n",
    "# tmp_test = np.hstack((X_test, X_test**2))\n",
    "# RF.fit(tmp_train, Y_train)\n",
    "# predictions = RF.predict(tmp_test)\n",
    "\n",
    "# #RF.fit(X_train, Y_train)\n",
    "# #predictions = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Sample Linear Regression Testing\n",
    "# LR = LinearRegression()\n",
    "# LR.fit(X_train, Y_train)\n",
    "# predictions = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Linear Regression\n",
      "Fitting Ridge Regression\n",
      "Fitting Lasso\n",
      "Fitting Random Forest\n",
      "Fitting the Ensemble\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Lasso' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7c26f00f0eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m                                    'y':Y_train})\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfensemblefinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ridge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lasso'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfensemblefinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Lasso' object is not callable"
     ]
    }
   ],
   "source": [
    "# Build Ensemble Model\n",
    "print \"Fitting Linear Regression\"\n",
    "LR.fit(X_train, Y_train)\n",
    "\n",
    "print \"Fitting Ridge Regression\"\n",
    "Ridge.fit(X_train, Y_train)\n",
    "\n",
    "print \"Fitting Lasso\"\n",
    "Lasso.fit(X_train, Y_train)\n",
    "\n",
    "print \"Fitting Random Forest\"\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "print \"Fitting the Ensemble\"\n",
    "lr_predictions = LR.predict(X_train)\n",
    "ridge_predictions = Ridge.predict(X_train)\n",
    "lasso_predictions = Lasso.predict(X_train)\n",
    "rf_predictions = RF.predict(X_train)\n",
    "\n",
    "dfensemblefinal = pd.DataFrame.from_dict({'lr':lr_predictions,\n",
    "                                   'ridge':ridge_predictions,\n",
    "                                   'lasso':lasso_predictions, \n",
    "                                   'rf':rf_predictions,\n",
    "                                   'y':Y_train})\n",
    "\n",
    "est = linear_model.Lasso(alpha=.01, selection='random')\n",
    "est.fit(dfensemblefinal[['lr', 'ridge', 'lasso', 'rf']].values, dfensemblefinal['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='random', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = linear_model.Lasso(alpha=.01, selection='random')\n",
    "est.fit(dfensemblefinal[['lr', 'ridge', 'lasso', 'rf']].values, dfensemblefinal['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.94883572])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the Ensemble to Predict the Test data\n",
    "print \"Predicting the X_test\"\n",
    "lr_predictions_test = LR.predict(X_test)\n",
    "ridge_predictions_test = Ridge.predict(X_test)\n",
    "lasso_predictions_test = Lasso.predict(X_test)\n",
    "rf_predictions_test = RF.predict(X_test)\n",
    "\n",
    "dfensembletestfinal=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   'rf':rf_predictions_test})\n",
    "\n",
    "predictions = est.predict(dfensembletestfinal[['lr', 'ridge', 'lasso', 'rf']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print predictions.shape\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"prediction.csv\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
