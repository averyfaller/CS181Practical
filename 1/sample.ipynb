{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Here we import that data from the CSV files and create a subset sample to do rapid training and validation cycles on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store gap values\n",
    "Y_train = df_train.gap.values\n",
    "\n",
    "# Take a sample with training and validation sets\n",
    "df_sample = df_train.sample(100000)\n",
    "msk = np.random.rand(len(df_sample)) < 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Here we extract features from the SMILES string and winnow down the existing features to create a more robust feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeFeatures(df):\n",
    "    \n",
    "    ##########################\n",
    "    ### DROP EMPTY COLUMNS ###\n",
    "    ##########################\n",
    "    # Remove 0 columns (columns with no data)\n",
    "    zero_cols = []\n",
    "    for i in range(1,257):\n",
    "        if df['feat_%03d' % i].sum() == 0:\n",
    "            zero_cols.append('feat_%03d' % i)\n",
    "    df = df.drop(zero_cols, axis=1)\n",
    "    \n",
    "    \n",
    "    ##############################\n",
    "    ### SMILE CHARACTER COUNTS ###\n",
    "    ##############################\n",
    "    smiles = df.smiles\n",
    "    smileydict = smiles.map(lambda x: dict(Counter(x)))\n",
    "    smile_alphabet=list(set(''.join(smiles.iloc[0:50])))\n",
    "    for smile in smile_alphabet:\n",
    "        smilechar = smile\n",
    "        if smile == '=':\n",
    "            smilechar = 'equal'\n",
    "        df['smile_'+smilechar] = smileydict.map(lambda x: x[smile] if smile in x.keys() else 0)\n",
    "        \n",
    "    \n",
    "    ###########################\n",
    "    ### FEATURE ENGINEERING ###\n",
    "    ###########################\n",
    "    #smiles_len = np.vstack(df_all.smiles.astype(str).apply(lambda x: len(x)))\n",
    "    #df_all['smiles_len'] = pd.DataFrame(smiles_len)\n",
    "\n",
    "    # Add length of smile\n",
    "    df['smile_length'] = df.smiles.map(lambda x: len(x))\n",
    "\n",
    "    # Add number of C's divided by length\n",
    "    df['smile_percentc'] = (df.smile_c / df.smile_length)\n",
    "    df['smile_percentC'] = (df.smile_C / df.smile_length)\n",
    "\n",
    "    # Count specific molecules\n",
    "    # [nH]\n",
    "    df['smile_nh'] = df.smiles.map(lambda x: x.count('[nH]'))\n",
    "    df['smile_si'] = df.smiles.map(lambda x: x.count('Si'))\n",
    "    df['smile_sih2'] = df.smiles.map(lambda x: x.count('[SiH2]'))\n",
    "    df['smile_se'] = df.smiles.map(lambda x: x.count('[se]'))\n",
    "    df['smile_CdoubleC'] = df.smiles.map(lambda x: x.count('C=C'))\n",
    "    df['smile_doubleC'] = df.smiles.map(lambda x: x.count('CC'))\n",
    "    df['smile_doublec'] = df.smiles.map(lambda x: x.count('cc'))\n",
    "    df['smile_triplec'] = df.smiles.map(lambda x: x.count('ccc'))\n",
    "    df['smile_quadc'] = df.smiles.map(lambda x: x.count('cccc'))\n",
    "    df['smile_quintc'] = df.smiles.map(lambda x: x.count('ccccc'))\n",
    "    #df['smile_c2'] = df.smiles.map(lambda x: x.count('c2'))\n",
    "    #df['smile_c3'] = df.smiles.map(lambda x: x.count('c3'))\n",
    "    #df['smile_c4'] = df.smiles.map(lambda x: x.count('c4'))\n",
    "\n",
    "    df['smile_C1equalCc2'] = df.smiles.map(lambda x: x.count('C1=Cc2'))\n",
    "    df['smile_C1'] = df.smiles.map(lambda x: x.count('C1'))\n",
    "    df['smile_c1'] = df.smiles.map(lambda x: x.count('c1'))\n",
    "    df['smile_equalCCCequal'] = df.smiles.map(lambda x: x.count('=CCC='))\n",
    "    df['smile_equalCCequal'] = df.smiles.map(lambda x: x.count('=CC='))\n",
    "    df['smile_equalCequal'] = df.smiles.map(lambda x: x.count('=C='))\n",
    "    df['smile_C1equalCCequalC'] = df.smiles.map(lambda x: x.count('C1=CC=C'))\n",
    "\n",
    "    # Parentheses molecules\n",
    "    df['smile_parenC1'] = df.smiles.map(lambda x: x.count('(C1)'))\n",
    "    df['smile_parenc1'] = df.smiles.map(lambda x: x.count('(c1)'))\n",
    "    df['smile_parencc1'] = df.smiles.map(lambda x: x.count('(cc1)'))\n",
    "    df['smile_pareno1'] = df.smiles.map(lambda x: x.count('(o1)'))\n",
    "    df['smile_parens1'] = df.smiles.map(lambda x: x.count('(s1)'))\n",
    "    df['smile_parenccc4mol'] = df.smiles.map(lambda x: x.count('(ccc4=C[SiH2]C=c34)'))\n",
    "    df['smile_parenccinnermol'] = df.smiles.map(lambda x: x.count('(cc(-c3ccco3)c3=CCC=c13)'))\n",
    "    df['smile_parennegc3cco3'] = df.smiles.map(lambda x: x.count('(-c3ccco3)'))\n",
    "    df['smile_parenncc3c12'] = df.smiles.map(lambda x: x.count('(ncc3c12)'))\n",
    "    df['smile_parenccc34'] = df.smiles.map(lambda x: x.count('(ccc34)'))\n",
    "    df['smile_parencc4ccc3c2cn1'] = df.smiles.map(lambda x: x.count('(cc4ccc3c2cn1)'))\n",
    "\n",
    "    # Special\n",
    "    df['smile_percent_aromatic'] = (df.smile_c + df.smile_o + df.smile_n + df.smile_s / df.smile_length)\n",
    "\n",
    "    # Start\n",
    "    df['smile_start_C1'] = df.smiles.map(lambda x: x.startswith('C1'))\n",
    "    df['smile_start_C1equal'] = df.smiles.map(lambda x: x.startswith('C1='))\n",
    "    df['smile_start_c1'] = df.smiles.map(lambda x: x.startswith('c1'))\n",
    "    df['smile_start_cc1'] = df.smiles.map(lambda x: x.startswith('cc1'))\n",
    "    df['smile_start_c1sc'] = df.smiles.map(lambda x: x.startswith('c1sc'))\n",
    "    df['smile_start_c1ccc'] = df.smiles.map(lambda x: x.startswith('c1ccc'))\n",
    "    df['smile_start_nH'] = df.smiles.map(lambda x: x.startswith('[nH]'))\n",
    "    df['smile_start_C1equalCCequalC'] = df.smiles.map(lambda x: x.startswith('C1=CC=C'))\n",
    "\n",
    "    # End\n",
    "    df['smile_end_c1ccc'] = df.smiles.map(lambda x: x.endswith('c1ccc'))\n",
    "    df['smile_end_o1'] = df.smiles.map(lambda x: x.endswith('o1'))\n",
    "    df['smile_end_ccsc12'] = df.smiles.map(lambda x: x.endswith('ccsc12'))\n",
    "\n",
    "    #df['smile_percent_bond'] = df.smile_equal / df.smile_length\n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ### DROP UNNECESSARY COLUMNS ###\n",
    "    ################################    \n",
    "    df = df.drop('smile_length', axis=1)\n",
    "    df = df.drop(['smiles'], axis=1)\n",
    "    \n",
    "    \n",
    "    # Return the data frame with all of the new features added in\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'feat_002'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9ce8658de7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakeFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b8c085a1216f>\u001b[0m in \u001b[0;36mmakeFeatures\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mzero_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m257\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feat_%03d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mzero_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feat_%03d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1967\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1968\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1969\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1976\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1092\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3211\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3213\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Avery/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1757\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   1758\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1759\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1761\u001b[0m         indexer = self.get_indexer([key], method=method,\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3979)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:3843)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'feat_002'"
     ]
    }
   ],
   "source": [
    "df_sample = makeFeatures(df_sample)\n",
    "df_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sample Shape (80033, 94)\n",
      "Y Training Sample Shape (80033,)\n",
      "Test Sample Shape (19967, 94)\n",
      "Y Test Sample Shape (19967,)\n"
     ]
    }
   ],
   "source": [
    "# Create the training sample\n",
    "df_sample_train = df_sample[msk]\n",
    "Y_sample_train = df_sample_train.gap.values\n",
    "df_sample_train = df_sample_train.drop(['gap'], axis=1)\n",
    "\n",
    "# Create the testing sample\n",
    "df_sample_test = df_sample[~msk]\n",
    "Y_sample_test = df_sample_test.gap.values\n",
    "df_sample_test = df_sample_test.drop(['gap'], axis=1)\n",
    "\n",
    "print \"Training Sample Shape\", df_sample_train.shape\n",
    "print \"Y Training Sample Shape\", Y_sample_train.shape\n",
    "print \"Test Sample Shape\", df_sample_test.shape\n",
    "print \"Y Test Sample Shape\", Y_sample_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Here we test out a series of models on the training and valida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.207\n",
      "Variance score: 0.740\n"
     ]
    }
   ],
   "source": [
    "# Sample Linear Regression Testing\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "LR.fit(df_sample_train, Y_sample_train)\n",
    "\n",
    "# The coefficients\n",
    "#print('Coefficients: \\n', LR.coef_)\n",
    "# RMSE\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((LR.predict(df_sample_test) - Y_sample_test) ** 2)))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.3f' % LR.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TOO SLOW!\n",
    "# Sample Polynomial Interpolation Testing\n",
    "#Poly = make_pipeline(PolynomialFeatures(degree), Ridge())\n",
    "#Poly.fit(df_sample_train, Y_sample_train)\n",
    "\n",
    "#print \"RMSE: %.3f\" % np.sqrt(np.mean((Poly.predict(df_sample_test) - Y_sample_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.209\n",
      "Variance score: 0.741\n"
     ]
    }
   ],
   "source": [
    "# Sample Ridge Testing\n",
    "Ridge = linear_model.Ridge(alpha = .001)\n",
    "\n",
    "Ridge.fit(df_sample_train, Y_sample_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Ridge.predict(df_sample_test) - Y_sample_test) ** 2)))\n",
    "print('Variance score: %.3f' % Ridge.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.213\n",
      "Variance score: 0.729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/linear_model/coordinate_descent.py:466: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Sample Lasso Testing\n",
    "Lasso = linear_model.Lasso(alpha = .001)\n",
    "\n",
    "Lasso.fit(df_sample_train, Y_sample_train)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((Lasso.predict(df_sample_test) - Y_sample_test) ** 2)))\n",
    "print('Variance score: %.3f' % Lasso.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.186\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "KNN = neighbors.KNeighborsRegressor(n_neighbors=12)\n",
    "\n",
    "KNN.fit(df_sample_train, Y_sample_train)\n",
    "\n",
    "#print \"N_neighbors: %d\" % 12\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((KNN.predict(df_sample_test) - Y_sample_test) ** 2)))\n",
    "#print('Variance score: %.3f' % KNN.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting\n",
      "RMSE: 0.150\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Testing\n",
    "RF = RandomForestRegressor(n_estimators=40, min_samples_split=8)\n",
    "RF.fit(df_sample_train, Y_sample_train)\n",
    "print \"Finished fitting\"\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((RF.predict(df_sample_test) - Y_sample_test) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building an Ensemble\n",
    "lr_predictions = LR.predict(df_sample_train)\n",
    "ridge_predictions = Ridge.predict(df_sample_train)\n",
    "lasso_predictions = Lasso.predict(df_sample_train)\n",
    "knn_predictions = KNN.predict(df_sample_train)\n",
    "rf_predictions = RF.predict(df_sample_train)\n",
    "\n",
    "\n",
    "dfensemble=pd.DataFrame.from_dict({'lr':lr_predictions,\n",
    "                                   'ridge':ridge_predictions,\n",
    "                                   'lasso':lasso_predictions, \n",
    "                                   'knn':knn_predictions,\n",
    "                                   'rf':rf_predictions,\n",
    "                                   'y':Y_sample_train})\n",
    "\n",
    "est = LinearRegression()\n",
    "est.fit(dfensemble[['lr', 'ridge', 'lasso', 'knn', 'rf']].values, dfensemble['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.156\n"
     ]
    }
   ],
   "source": [
    "# Testing the Ensemble\n",
    "lr_predictions_test = LR.predict(df_sample_test)\n",
    "ridge_predictions_test = Ridge.predict(df_sample_test)\n",
    "lasso_predictions_test = Lasso.predict(df_sample_test)\n",
    "knn_predictions_test = KNN.predict(df_sample_test)\n",
    "rf_predictions_test = RF.predict(df_sample_test)\n",
    "\n",
    "dfensembletest=pd.DataFrame.from_dict({'lr':lr_predictions_test,\n",
    "                                   'ridge':ridge_predictions_test,\n",
    "                                   'lasso':lasso_predictions_test,\n",
    "                                   'knn':knn_predictions_test,\n",
    "                                   'rf':rf_predictions_test,\n",
    "                                   'y':Y_sample_test})\n",
    "\n",
    "epreds = est.predict(dfensembletest[['lr', 'ridge', 'lasso', 'knn', 'rf']].values)\n",
    "\n",
    "print(\"RMSE: %.3f\" % np.sqrt(np.mean((epreds - Y_sample_test) ** 2)))\n",
    "#print('Variance score: %.3f' % est.score(df_sample_test, Y_sample_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'smiles', u'feat_001', u'feat_002', u'feat_003', u'feat_004',\n",
      "       u'feat_005', u'feat_006', u'feat_007', u'feat_008', u'feat_009',\n",
      "       ...\n",
      "       u'feat_248', u'feat_249', u'feat_250', u'feat_251', u'feat_252',\n",
      "       u'feat_253', u'feat_254', u'feat_255', u'feat_256', u'gap'],\n",
      "      dtype='object', length=258)\n",
      "Index([u'Id', u'smiles', u'feat_001', u'feat_002', u'feat_003', u'feat_004',\n",
      "       u'feat_005', u'feat_006', u'feat_007', u'feat_008',\n",
      "       ...\n",
      "       u'feat_247', u'feat_248', u'feat_249', u'feat_250', u'feat_251',\n",
      "       u'feat_252', u'feat_253', u'feat_254', u'feat_255', u'feat_256'],\n",
      "      dtype='object', length=258)\n",
      "Train features: (1000000, 94)\n",
      "Train gap: (1000000,)\n",
      "Test features: (824230, 94)\n"
     ]
    }
   ],
   "source": [
    "# Clean up Actual Training and Testing Data\n",
    "X_train = makeFeatures(df_train)\n",
    "X_test = makeFeatures(df_test)\n",
    "\n",
    "# Delete 'gap' column in training\n",
    "X_train = X_train.drop(['gap'], axis=1)\n",
    "\n",
    "# Delete 'Id' column in testing\n",
    "X_test = X_test.drop(['Id'], axis=1)\n",
    "\n",
    "print \"Train features:\", X_train.shape\n",
    "print \"Train gap:\", Y_train.shape\n",
    "print \"Test features:\", X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Random Forest Prediction\n",
    "RF = RandomForestRegressor(n_estimators=40, min_samples_split=8)\n",
    "RF.fit(X_train, Y_train)\n",
    "\n",
    "RF_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3c9c92b6e066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRF_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "RF_predred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"RF.csv\", RF_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
