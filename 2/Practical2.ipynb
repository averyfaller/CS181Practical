{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "call_set = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# UTILITIES\n",
    "# these are the fifteen malware classes we're looking for\n",
    "malware_classes = [\"Agent\", \"AutoRun\", \"FraudLoad\", \"FraudPack\", \"Hupigon\", \"Krap\",\n",
    "           \"Lipler\", \"Magania\", \"None\", \"Poison\", \"Swizzor\", \"Tdss\",\n",
    "           \"VB\", \"Virut\", \"Zbot\"]\n",
    "\n",
    "# a function for writing predictions in the required format\n",
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for \n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_to_set(tree):\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        call_set.add(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_matrix(start_index, end_index, direc=\"train\"):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break\n",
    "\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(malware_classes.index(clazz))\n",
    "\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        add_to_set(tree)\n",
    "        this_row = call_feats(tree)\n",
    "        if X is None:\n",
    "            X = this_row \n",
    "        else:\n",
    "            X = np.vstack((X, this_row))\n",
    "\n",
    "    return X, np.array(classes), ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_calls = [\n",
    "    'processes', 'query_value', 'read_section', 'read_section_names', 'read_value', \n",
    "        'recv_socket', 'remove_directory', 'revert_to_self', 'send_socket', \n",
    "        'set_file_attributes', 'set_file_time', 'set_system_time', 'set_thread_context', \n",
    "        'set_value', 'set_windows_hook', 'show_window', 'sleep', 'start_service', 'thread',\n",
    "        'trimmed_bytes', 'unload_driver', 'vm_allocate', 'vm_mapviewofsection', 'vm_protect',\n",
    "        'vm_read', 'vm_write', 'write_value', 'open_key', 'create_open_file', 'get_host_by_name', \n",
    "        'load_dll', 'create_mutex', 'load_image', 'create_file', 'get_file_attributes', 'open_process',\n",
    "        'find_window', 'com_create_instance', 'destroy_window', 'impersonate_user', 'dump_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def call_feats(tree):\n",
    "    \n",
    "#     bigram_calls = []\n",
    "#     for a_call in good_calls:\n",
    "#         for b_call in good_calls:\n",
    "#             bigram_calls.append(a_call + '_' + b_call)\n",
    "            \n",
    "#     combined_calls = good_calls + bigram_calls\n",
    "\n",
    "    call_counter = {}\n",
    "    last_call='start'\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        # Add specific call counts\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 1\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "            \n",
    "#         # Bigram Calls\n",
    "#         combo = last_call + '_' + call\n",
    "#         if combo not in call_counter:\n",
    "#             call_counter[combo] = 1\n",
    "#         #else:\n",
    "#         #    call_counter[combo] += 1\n",
    "#         last_call = call\n",
    "            \n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix (training set):\n",
      "[[  1.00000000e+00   2.42000000e+02   0.00000000e+00 ...,   4.20000000e+01\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   2.00400000e+03   1.00000000e+00 ...,   6.50000000e+01\n",
      "    1.20000000e+01   3.43400000e+03]\n",
      " [  1.00000000e+00   7.00000000e+00   0.00000000e+00 ...,   3.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  1.00000000e+00   5.34000000e+02   0.00000000e+00 ...,   0.00000000e+00\n",
      "    3.00000000e+00   2.60000000e+01]\n",
      " [  1.00000000e+00   2.60000000e+02   0.00000000e+00 ...,   7.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.00000000e+00   2.42000000e+02   0.00000000e+00 ...,   4.20000000e+01\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "Classes (training set):\n",
      "[ 8  6 12 ..., 10  8  8]\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA\n",
    "X_train, t_train, train_ids = create_data_matrix(0, 2777, TRAIN_DIR)\n",
    "X_valid, t_valid, valid_ids = create_data_matrix(2777, 3086, TRAIN_DIR)\n",
    "X_train_all, t_train_all, train_all_ids = create_data_matrix(0, 3086, TRAIN_DIR)\n",
    "\n",
    "print 'Data matrix (training set):'\n",
    "print X_train\n",
    "print 'Classes (training set):'\n",
    "print t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING DATA\n",
    "X_test_all, t_test_all, test_all_ids = create_data_matrix(0, 3724, TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "Score of validation set: 0.770227\n"
     ]
    }
   ],
   "source": [
    "# Try SVM\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, t_train)\n",
    "print \"SVM\"\n",
    "print \"Score of validation set: %f\" % clf.score(X_valid, t_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forests\n",
      "For n = 1, score was: 0.864078\n",
      "For n = 5, score was: 0.867314\n",
      "For n = 7, score was: 0.889968\n",
      "For n = 8, score was: 0.889968\n",
      "For n = 9, score was: 0.889968\n",
      "For n = 10, score was: 0.893204\n",
      "For n = 11, score was: 0.893204\n",
      "For n = 12, score was: 0.893204\n",
      "For n = 13, score was: 0.909385\n",
      "For n = 14, score was: 0.902913\n",
      "For n = 15, score was: 0.906149\n",
      "For n = 20, score was: 0.899676\n",
      "For n = 25, score was: 0.912621\n",
      "For n = 30, score was: 0.915858\n",
      "For n = 35, score was: 0.902913\n",
      "For n = 40, score was: 0.899676\n",
      "For n = 50, score was: 0.909385\n",
      "For n = 100, score was: 0.909385\n",
      "For n = 200, score was: 0.902913\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "print \"Random Forests\"\n",
    "ns = [1,5,7,8,9,10,11,12,13,14,15,20,25,30,35,40,50,100,200]\n",
    "for n in ns:\n",
    "    rf = RandomForestClassifier(n_estimators=n)\n",
    "    rf.fit(X_train, t_train)\n",
    "    print \"For n = %d, score was: %f\" % (n, rf.score(X_valid, t_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score was: 0.912621\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30, min_samples_split=3)\n",
    "rf.fit(X_train, t_train)\n",
    "print \"Score was: %f\" % (rf.score(X_valid, t_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "For n = 1, score was: 0.844660\n",
      "For n = 2, score was: 0.844660\n",
      "For n = 3, score was: 0.864078\n",
      "For n = 4, score was: 0.864078\n",
      "For n = 5, score was: 0.857605\n",
      "For n = 6, score was: 0.864078\n",
      "For n = 7, score was: 0.854369\n",
      "For n = 8, score was: 0.857605\n",
      "For n = 10, score was: 0.851133\n",
      "For n = 20, score was: 0.844660\n",
      "For n = 25, score was: 0.841424\n",
      "For n = 30, score was: 0.831715\n",
      "For n = 50, score was: 0.818770\n",
      "For n = 100, score was: 0.773463\n",
      "For n = 200, score was: 0.728155\n"
     ]
    }
   ],
   "source": [
    "# Try KNeighborsClassifier\n",
    "ns = [1,2,3,4,5,6,7,8,10,20,25,30,50,100,200]\n",
    "kneighborsscores = []\n",
    "print \"KNeighborsClassifier\"\n",
    "for n in ns:\n",
    "    nn = KNeighborsClassifier(n_neighbors=n)\n",
    "    nn.fit(X_train, t_train)\n",
    "    score = nn.score(X_valid, t_valid)\n",
    "    kneighborsscores.append(score)\n",
    "    print \"For n = %d, score was: %f\" % (n, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score was: 0.883495\n"
     ]
    }
   ],
   "source": [
    "kneighborsscores2 = []\n",
    "nn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
    "nn.fit(X_train, t_train)\n",
    "score = nn.score(X_valid, t_valid)\n",
    "kneighborsscores2.append(score)\n",
    "print \"Score was: %f\" % (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score was: 0.889968\n"
     ]
    }
   ],
   "source": [
    "kneighborsscores2 = []\n",
    "nn = KNeighborsClassifier(n_neighbors=6, weights='distance', p=1)\n",
    "nn.fit(X_train, t_train)\n",
    "score = nn.score(X_valid, t_valid)\n",
    "kneighborsscores2.append(score)\n",
    "print \"Score was: %f\" % (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate predictions on test set for the best model\n",
    "\n",
    "nn = KNeighborsClassifier(n_neighbors=6, weights='distance', p=1)\n",
    "nn.fit(X_train_all, t_train_all)\n",
    "test_predictions = nn.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=30, min_samples_split=3)\n",
    "rf.fit(X_train_all, t_train_all)\n",
    "test_predictions = rf.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, ids, predictions):\n",
    "    zips = zip(ids, predictions)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(zips):\n",
    "            f.write(str(p[0]) + \",\" + str(p[1]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_to_file(\"prediction.csv\", test_all_ids, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00278ec420236020d6121dffe0cc20034422e7228.Lipler.xml\n",
      "[  1.00000000e+00   2.00400000e+03   1.00000000e+00   0.00000000e+00\n",
      "   5.10000000e+01   2.11000000e+02   1.00000000e+00   0.00000000e+00\n",
      "   1.70000000e+01   2.00000000e+01   1.80000000e+01   0.00000000e+00\n",
      "   0.00000000e+00   7.00000000e+01   2.80000000e+01   4.00000000e+00\n",
      "   2.54000000e+02   0.00000000e+00   4.10000000e+01   2.05000000e+02\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   3.65000000e+02\n",
      "   0.00000000e+00   0.00000000e+00   3.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "# Run this to see what call_feats returns\n",
    "direc = \"train\"\n",
    "for idx, datafile in enumerate(os.listdir(direc)):\n",
    "    if idx == 1:\n",
    "        print datafile\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        feats = call_feats(tree)\n",
    "        \n",
    "#         for el in tree.iter():\n",
    "#             print el.tag\n",
    "        print feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
