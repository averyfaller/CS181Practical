{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "call_set = set([])\n",
    "\n",
    "malware_classes = [\"Agent\", \"AutoRun\", \"FraudLoad\", \"FraudPack\", \"Hupigon\", \"Krap\",\n",
    "           \"Lipler\", \"Magania\", \"None\", \"Poison\", \"Swizzor\", \"Tdss\",\n",
    "           \"VB\", \"Virut\", \"Zbot\"]\n",
    "\n",
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for \n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))\n",
    "\n",
    "def add_to_set(tree):\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        call_set.add(call)\n",
    "\n",
    "def create_data_matrix(start_index, end_index, direc=\"train\"):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break\n",
    "\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(malware_classes.index(clazz))\n",
    "\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        add_to_set(tree)\n",
    "        this_row = call_feats(tree)\n",
    "        if X is None:\n",
    "            X = this_row \n",
    "        else:\n",
    "            X = np.vstack((X, this_row))\n",
    "\n",
    "    return X, np.array(classes), ids\n",
    "\n",
    "def add_count(feature_dict, feature_name):\n",
    "    if feature_name not in feature_dict:\n",
    "        feature_dict[feature_name] = 1\n",
    "    else:\n",
    "        feature_dict[feature_name] += 1\n",
    "    return feature_dict\n",
    "\n",
    "def call_feats(tree):\n",
    "    include_other_features = True\n",
    "    include_first_calls = True\n",
    "    include_second_calls = True\n",
    "    include_call_pairs = False\n",
    "\n",
    "    all_calls = ['recv_socket', 'create_open_file', 'sleep', 'open_scmanager', 'load_driver', \n",
    "              'get_host_by_addr', 'create_interface', 'create_mutex', 'set_value', 'enum_items', \n",
    "              'get_computer_name', 'read_value', 'write_value', 'change_service_config', \n",
    "              'copy_file', 'exit_windows', 'connect_share', 'enum_modules', 'bind_socket', \n",
    "              'enum_keys', 'delete_value', 'enum_types', 'open_service', 'processes', \n",
    "              'add_share', 'create_socket', 'enum_user', 'dump_line', 'unload_driver', \n",
    "              'enum_values', 'thread', 'load_dll', 'create_window', 'read_section_names', \n",
    "              'com_create_instance', 'message', 'get_userinfo', 'get_file_attributes', 'find_file', \n",
    "              'open_file', 'get_username', 'create_service', 'query_value', 'create_file', \n",
    "              'move_file', 'open_key', 'send_socket', 'vm_write', 'delete_file', \n",
    "              'create_process_as_user', 'get_system_time', 'create_mailslot', 'com_createole_object', \n",
    "              'listen_socket', 'enum_share', 'open_mutex', 'vm_protect', 'all_section', \n",
    "              'vm_mapviewofsection', 'get_windows_directory', 'enum_processes', 'open_url', \n",
    "              'download_file', 'com_get_class_object', 'kill_process', 'load_image', 'delete_share', \n",
    "              'create_process', 'logon_as_user', 'get_system_directory', 'set_thread_context', \n",
    "              'create_process_nt', 'destroy_window', 'vm_allocate', 'enum_handles', 'connect_socket', \n",
    "              'set_file_time', 'start_service', 'create_thread_remote', 'show_window', 'open_process', \n",
    "              'impersonate_user', 'connect', 'enum_services', 'process', 'vm_read', 'check_for_debugger', \n",
    "              'query_keyinfo', 'delete_service', 'read_section', 'enum_window', 'set_system_time', \n",
    "              'add_netjob', 'ping', 'set_windows_hook', 'control_service', 'accept_socket', \n",
    "              'trimmed_bytes', 'download_file_to_cache', 'find_window', 'get_host_by_name', \n",
    "              'set_file_attributes', 'revert_to_self', 'create_key', 'create_thread', 'enum_subtypes', \n",
    "              'delete_key', 'create_directory', 'remove_directory', 'create_namedpipe']\n",
    "\n",
    "    first_calls = map(lambda call: \"fc_\" + call, all_calls)\n",
    "\n",
    "    second_calls = map(lambda call: \"sc_\" + call, all_calls)\n",
    "\n",
    "    call_pairs = map(lambda call_one: map(lambda call_two: call_one + \"_\" + call_two, second_calls), first_calls)\n",
    "\n",
    "    all_features = all_calls\n",
    "\n",
    "    if include_other_features:\n",
    "        other_features = ['Administrator', 'SYSTEM', 'NETZWERKDIENST', 'LOKALER DIENST', \n",
    "                      'SCM', 'InjectedCode', 'SvcHost', 'CreateProcess', 'BHOInstalled', 'DCOMService', 'AnalysisTarget',\n",
    "                     'NormalTermination', 'Unknown', 'KilledByWindowsLoader', 'Timeout']\n",
    "        all_features += other_features\n",
    "    if include_first_calls:\n",
    "        all_features += first_calls\n",
    "    if include_second_calls:\n",
    "        all_features += second_calls\n",
    "    if include_call_pairs:\n",
    "        all_features += call_pairs\n",
    "\n",
    "    feature_dict = {}\n",
    "    last_call='start'\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        feature_dict = add_count(feature_dict, call)\n",
    "    \n",
    "    # Attempt to add arguments of username, startreason, and terminationreason\n",
    "    if include_other_features:\n",
    "        root = tree.getroot()\n",
    "        for process in root.findall('process[@username]'):\n",
    "            username = process.attrib['username']\n",
    "            feature_dict = add_count(feature_dict, username)\n",
    "        for process in root.findall('process[@startreason]'):\n",
    "            startreason = process.attrib['startreason']\n",
    "            feature_dict = add_count(feature_dict, startreason)\n",
    "        for process in root.findall('process[@terminationreason]'):\n",
    "            terminationreason = process.attrib['terminationreason']\n",
    "            feature_dict = add_count(feature_dict, terminationreason)\n",
    "\n",
    "    # Attempt to add first and second calls\n",
    "    j = 0\n",
    "    for call in root.findall('process/thread/all_section/'):\n",
    "        name = call.tag\n",
    "        if (name != 'load_image') and (name != 'load_dll'): \n",
    "            j += 1\n",
    "            if include_first_calls and j == 1:\n",
    "                first_call = 'fc_' + name\n",
    "                feature_dict = add_count(feature_dict, first_call)\n",
    "            if include_second_calls and j == 2:\n",
    "                second_call = 'sc_' + name\n",
    "                feature_dict = add_count(feature_dict, second_call)\n",
    "                break\n",
    "    \n",
    "    # Attempt to add call-pairs, which, in theory, help account for sequencing of calls.\n",
    "    # This perhaps should be extended to call-triplets, etc.\n",
    "    if include_call_pairs:\n",
    "        for idx, call in enumerate(root.findall('process/thread/all_section/')):\n",
    "            if idx == 1:\n",
    "                second_call = call.tag\n",
    "            elif idx >= 2:\n",
    "                first_call = second_call\n",
    "                second_call = call.tag\n",
    "                call_pair = \"fc_\" + first_call + \"_sc_\" + second_call\n",
    "                feature_dict = add_count(feature_dict, call_pair)\n",
    "            \n",
    "    call_feat_array = np.zeros(len(all_features))\n",
    "    for i in range(len(all_features)):\n",
    "        call = all_features[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in feature_dict:\n",
    "            call_feat_array[i] = feature_dict[call]\n",
    "\n",
    "    return call_feat_array\n",
    "\n",
    "def write_to_file(filename, ids, predictions):\n",
    "    zips = zip(ids, predictions)\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(zips):\n",
    "            f.write(str(p[0]) + \",\" + str(p[1]) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_all, t_train_all, train_all_ids = create_data_matrix(0, 3086, TRAIN_DIR)\n",
    "X_train, X_valid, t_train, t_valid = train_test_split(X_train_all, t_train_all, test_size=0.20, random_state=37)\n",
    "X_test_all, t_test_all, test_all_ids = create_data_matrix(0, 3724, TEST_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 345)\n",
      "(618, 345)\n",
      "SVM Score was: 0.822006\n",
      "RandomForest Score was: 0.889968\n",
      "LogisticRegression Score was: 0.855987\n",
      "GaussianNB Score was: 0.404531\n",
      "KNeighbors Score was: 0.852751\n",
      "RadiusNeighbors Score was: 0.752427\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print X_valid.shape\n",
    "\n",
    "sv = svm.SVC(kernel='poly')\n",
    "sv.fit(X_train, t_train)\n",
    "print \"SVM Score was: %f\" % sv.score(X_valid, t_valid)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=30, min_samples_split=1, random_state=37)\n",
    "rf.fit(X_train, t_train)\n",
    "print \"RandomForest Score was: %f\" % (rf.score(X_valid, t_valid))\n",
    "\n",
    "lr = LogisticRegression(penalty='l2',solver='newton-cg',max_iter=500)\n",
    "lr.fit(X_train, t_train)\n",
    "print \"LogisticRegression Score was: %f\" % (lr.score(X_valid, t_valid))\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, t_train)\n",
    "print \"GaussianNB Score was: %f\" % (clf.score(X_valid, t_valid))\n",
    "\n",
    "nn = KNeighborsClassifier(n_neighbors=6, weights='uniform')\n",
    "nn.fit(X_train, t_train)\n",
    "score = nn.score(X_valid, t_valid)\n",
    "print \"KNeighbors Score was: %f\" % (score)\n",
    "\n",
    "rnc = RadiusNeighborsClassifier(radius=6,outlier_label=8, p=2)\n",
    "rnc.fit(X_train, t_train)\n",
    "print \"RadiusNeighbors Score was: %f\" % (rnc.score(X_valid, t_valid))\n",
    "\n",
    "# Get predictions\n",
    "rf = RandomForestClassifier(n_estimators=30, min_samples_split=1)\n",
    "rf.fit(X_train_all, t_train_all)\n",
    "test_predictions = rf.predict(X_test_all)\n",
    "\n",
    "write_to_file(\"prediction.csv\", test_all_ids, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
