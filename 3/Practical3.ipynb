{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/Avery/anaconda/lib/python2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import *\n",
    "\n",
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "# Hard-code file names\n",
    "train_file = 'train.csv'\n",
    "test_file  = 'test.csv'\n",
    "soln_file  = 'predictions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_data = {}\n",
    "user_ids = []\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = row[2]\n",
    "    \n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "            user_ids.append(user)\n",
    "        \n",
    "        train_data[user][artist] = int(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in train: 233286\n",
      "\n",
      "{'e3e0abcd-7671-4482-a9d8-462f5acc9be5': 64, '63011a8d-0117-4f7e-9991-1ef1f337ff70': 13, 'f4857fb9-e255-4dc6-bd01-e4ca7cc68544': 21, 'c485632c-b784-4ee9-8ea1-c5fb365681fc': 45, 'a96ac800-bfcb-412a-8a63-0a98df600700': 35, '8dd98bdc-80ec-4e93-8509-2f46bafc09a7': 23, '69837400-8e31-4949-aac2-00b46b4df126': 18, 'a3a92047-be1c-4f3e-8960-c4f8570984df': 81, '648615ca-ca74-460d-928a-2bae67ae6d14': 19, '0110e63e-0a9b-4818-af8e-41e180c20b9a': 22, '6ffb8ea9-2370-44d8-b678-e9237bbd347b': 56, '9fdaa16b-a6c4-4831-b87c-bc9ca8ce7eaa': 20, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 70, '9bf79f68-c064-44a1-8c2c-5764f1d7c016': 27, '4a4ee089-93b1-4470-af9a-6ff575d32704': 31, '9efff43b-3b29-4082-824e-bc82f646f93d': 22}\n",
      "{'8d18b680-368c-4649-a5e3-85e0c2dd6fc2': 51, 'a4a3048f-3968-4848-9f53-94e3d4f88b53': 47, '6ffb8ea9-2370-44d8-b678-e9237bbd347b': 86, '9c9f1380-2516-4fc9-a3e6-f9f61941d090': 145, 'eeb1195b-f213-4ce1-b28c-8565211f8e43': 708, '24ea074c-59cc-41c5-a5de-f68c2952965f': 135, '83e59f23-3b0b-4304-834d-5bcafd5df6d2': 65, 'be407b02-f3e6-4ed5-9489-f8e5f0ab36dc': 74, '487bfd74-71bf-46dd-b89c-80b7a0f06f2f': 120, '11ae9fbb-f3d7-4a47-936f-4c0a04d3b3b5': 455, 'b2dbfc09-b332-408b-a235-1850e41971c5': 98, 'eb3f70ce-f226-428f-8d7f-046c8dbfd98f': 271, '9a04dc8c-82f1-457a-a25a-3ff19e1b471e': 192, 'b09b5127-c62e-4bb2-b790-1e4aa18749ed': 113, 'ca5b38c2-f39d-45a4-ad3d-daf4448846ef': 57, 'ada7a83c-e3e1-40f1-93f9-3e73dbc9298a': 49, '66c662b6-6e2f-4930-8610-912e24c63ed1': 1679, 'dcb03ce3-67a5-4eb3-b2d1-2a12d93a38f3': 45, '72ae6caf-4f9f-407e-8c70-8cd195df955c': 164, '14b22b4b-06d5-4b82-8284-29d29b58945f': 77}\n"
     ]
    }
   ],
   "source": [
    "# Examine the data\n",
    "print \"Number of users in train: \" + str(len(user_ids))\n",
    "print \"\"\n",
    "for user_id in user_ids[1:3]:\n",
    "    print train_data[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174964\n",
      "58322\n"
     ]
    }
   ],
   "source": [
    "# Train-Test Split\n",
    "tt_X, tt_Y = cross_validation.train_test_split(user_ids, random_state=37)\n",
    "print len(tt_X)\n",
    "print len(tt_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GIVEN CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))\n",
    "\n",
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_medians:\n",
    "                soln_csv.writerow([id, user_medians[user]])\n",
    "            else:\n",
    "                print \"User\", id, \"not in training data.\"\n",
    "                soln_csv.writerow([id, global_median])\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
