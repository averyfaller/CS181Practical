{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import *\n",
    "\n",
    "# Predict via the user-specific median.\n",
    "# If the user has no data, use the global median.\n",
    "\n",
    "# Hard-code file names\n",
    "train_file = 'train.csv'\n",
    "test_file  = 'test.csv'\n",
    "soln_file  = 'predictions.csv'\n",
    "profiles_file = 'profiles.csv'\n",
    "artist_file = 'artists.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233286\n"
     ]
    }
   ],
   "source": [
    "# Load the profile data.\n",
    "profile_data = {}\n",
    "user_ids = []\n",
    "\n",
    "with open(profiles_file, 'r') as profile_fh:\n",
    "    profile_csv = csv.reader(profile_fh, delimiter=',', quotechar='\"')\n",
    "    next(profile_csv, None)\n",
    "    for row in profile_csv:\n",
    "        # user,sex,age,country\n",
    "        user    = row[0]\n",
    "        sex     = row[1]\n",
    "        age     = row[2]\n",
    "        country = row[3]\n",
    "\n",
    "        if age == '':\n",
    "            age = -1\n",
    "        if sex == '':\n",
    "            sex = 'u'\n",
    "    \n",
    "        if not user in profile_data:\n",
    "            profile_data[user] = {}\n",
    "            user_ids.append(user)\n",
    "        \n",
    "        profile_data[user]['sex'] = sex\n",
    "        profile_data[user]['age'] = int(age)\n",
    "        profile_data[user]['country'] = country\n",
    "\n",
    "print len(user_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in profiles: 233286\n",
      "\n",
      "{'country': 'Iceland', 'age': 29, 'sex': 'm'}\n",
      "{'country': 'United States', 'age': 30, 'sex': 'm'}\n",
      "{'country': 'Germany', 'age': 21, 'sex': 'm'}\n",
      "{'country': 'Netherlands', 'age': 24, 'sex': 'm'}\n",
      "{'country': 'United States', 'age': 22, 'sex': 'm'}\n",
      "{'country': 'United States', 'age': -1, 'sex': 'f'}\n",
      "{'country': 'Poland', 'age': -1, 'sex': 'f'}\n",
      "{'country': 'United States', 'age': -1, 'sex': 'm'}\n",
      "{'country': 'Ukraine', 'age': 16, 'sex': 'u'}\n",
      "{'country': 'Italy', 'age': 44, 'sex': 'm'}\n",
      "{'country': 'Russian Federation', 'age': 17, 'sex': 'm'}\n",
      "{'country': 'Germany', 'age': 25, 'sex': 'm'}\n",
      "{'country': 'Austria', 'age': 24, 'sex': 'm'}\n",
      "{'country': 'Australia', 'age': 22, 'sex': 'f'}\n",
      "{'country': 'Germany', 'age': 34, 'sex': 'm'}\n",
      "{'country': 'United States', 'age': -1, 'sex': 'm'}\n",
      "{'country': 'United States', 'age': 22, 'sex': 'm'}\n",
      "{'country': 'Canada', 'age': 22, 'sex': 'm'}\n",
      "{'country': 'Germany', 'age': -1, 'sex': 'm'}\n"
     ]
    }
   ],
   "source": [
    "print \"Number of users in profiles: \" + str(len(user_ids))\n",
    "print \"\"\n",
    "for user_id in user_ids[1:20]:\n",
    "    print profile_data[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create indicator variables\n",
    "columns = ['i_MALE','i_FEMALE']\n",
    "\n",
    "# Add countries\n",
    "for user_id in user_ids:\n",
    "    country = profile_data[user_id]['country']\n",
    "    if country not in columns:\n",
    "        columns.append(country)\n",
    "\n",
    "# Add ages\n",
    "ages = [15, 20, 25, 30, 35, 40, 45, 50, 55, 10000] # AGES\n",
    "columns.extend(ages)\n",
    "    \n",
    "# Construct matrix\n",
    "profile_matrix = np.zeros((len(user_ids), len(columns)))\n",
    "age_matrix = np.zeros((len(user_ids), len(ages)))\n",
    "for i, user_id in enumerate(user_ids):\n",
    "    profile = profile_data[user_id]\n",
    "\n",
    "    # Create indicator variable for MALE\n",
    "    if profile['sex'] == 'm':\n",
    "        profile_matrix[i, 0] = 1\n",
    "    # Create indicator variable for FEMALE    \n",
    "    elif profile['sex'] == 'f':\n",
    "        profile_matrix[i, 1] = 1\n",
    "        \n",
    "    # Add a 1 for the country indicator\n",
    "    country = profile['country']\n",
    "    country_col = columns.index(country)\n",
    "    profile_matrix[i, country_col] = 1\n",
    "\n",
    "    # TODO: Calculate median age, replace nulls with \n",
    "    \n",
    "    # Add age\n",
    "    index = 0\n",
    "    for j, age in enumerate(ages):\n",
    "        if profile['age'] < age:\n",
    "            index = j\n",
    "        else:\n",
    "            break\n",
    "    age_matrix[i, index] = 1\n",
    "    \n",
    "profile_matrix = np.hstack((profile_matrix, age_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the data\n",
    "profile_matrix.shape\n",
    "profile_matrix[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_pos_by_id = {}\n",
    "for i, user_id in enumerate(user_ids):\n",
    "    user_pos_by_id[user_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the artist data.\n",
    "artist_names = {}\n",
    "artist_ids = []\n",
    "\n",
    "with open(artist_file, 'r') as artist_fh:\n",
    "    artist_csv = csv.reader(artist_fh, delimiter=',', quotechar='\"')\n",
    "    next(artist_csv, None)\n",
    "    for row in artist_csv:\n",
    "        # user,sex,age,country\n",
    "        artist    = row[0]\n",
    "        name      = row[1]\n",
    "        \n",
    "        artist_names[artist] = name\n",
    "        artist_ids.append(artist)\n",
    "        \n",
    "artist_pos_by_id = {}\n",
    "for i, artist_id in enumerate(artist_ids):\n",
    "    artist_pos_by_id[artist_id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the training data.\n",
    "train_data = {}\n",
    "train_user_ids = []\n",
    "\n",
    "# TRAIN-TEST SPLIT FOR TESTING PURPOSES\n",
    "# Need to split on a per-user-artist level, not just per-user level\n",
    "train_train_data = {}\n",
    "train_test_data = {}\n",
    "\n",
    "with open(train_file, 'r') as train_fh:\n",
    "    train_csv = csv.reader(train_fh, delimiter=',', quotechar='\"')\n",
    "    next(train_csv, None)\n",
    "    for row in train_csv:\n",
    "        user   = row[0]\n",
    "        artist = row[1]\n",
    "        plays  = row[2]\n",
    "    \n",
    "        if not user in train_data:\n",
    "            train_data[user] = {}\n",
    "            train_user_ids.append(user)\n",
    "        \n",
    "        train_data[user][artist] = int(plays)\n",
    "        \n",
    "        # Build train and test split\n",
    "        if np.random.uniform(0,1,1) < .75:\n",
    "            if not user in train_train_data:\n",
    "                train_train_data[user] = {}\n",
    "            train_train_data[user][artist] = int(plays)\n",
    "        else:\n",
    "            if not user in train_test_data:\n",
    "                train_test_data[user] = {}\n",
    "            train_test_data[user][artist] = int(plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in train: 233286\n",
      "\n",
      "{'e3e0abcd-7671-4482-a9d8-462f5acc9be5': 64, '63011a8d-0117-4f7e-9991-1ef1f337ff70': 13, 'f4857fb9-e255-4dc6-bd01-e4ca7cc68544': 21, 'c485632c-b784-4ee9-8ea1-c5fb365681fc': 45, 'a96ac800-bfcb-412a-8a63-0a98df600700': 35, '8dd98bdc-80ec-4e93-8509-2f46bafc09a7': 23, '69837400-8e31-4949-aac2-00b46b4df126': 18, 'a3a92047-be1c-4f3e-8960-c4f8570984df': 81, '648615ca-ca74-460d-928a-2bae67ae6d14': 19, '0110e63e-0a9b-4818-af8e-41e180c20b9a': 22, '6ffb8ea9-2370-44d8-b678-e9237bbd347b': 56, '9fdaa16b-a6c4-4831-b87c-bc9ca8ce7eaa': 20, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 70, '9bf79f68-c064-44a1-8c2c-5764f1d7c016': 27, '4a4ee089-93b1-4470-af9a-6ff575d32704': 31, '9efff43b-3b29-4082-824e-bc82f646f93d': 22}\n",
      "{'8d18b680-368c-4649-a5e3-85e0c2dd6fc2': 51, 'a4a3048f-3968-4848-9f53-94e3d4f88b53': 47, '6ffb8ea9-2370-44d8-b678-e9237bbd347b': 86, '9c9f1380-2516-4fc9-a3e6-f9f61941d090': 145, 'eeb1195b-f213-4ce1-b28c-8565211f8e43': 708, '24ea074c-59cc-41c5-a5de-f68c2952965f': 135, '83e59f23-3b0b-4304-834d-5bcafd5df6d2': 65, 'be407b02-f3e6-4ed5-9489-f8e5f0ab36dc': 74, '487bfd74-71bf-46dd-b89c-80b7a0f06f2f': 120, '11ae9fbb-f3d7-4a47-936f-4c0a04d3b3b5': 455, 'b2dbfc09-b332-408b-a235-1850e41971c5': 98, 'eb3f70ce-f226-428f-8d7f-046c8dbfd98f': 271, '9a04dc8c-82f1-457a-a25a-3ff19e1b471e': 192, 'b09b5127-c62e-4bb2-b790-1e4aa18749ed': 113, 'ca5b38c2-f39d-45a4-ad3d-daf4448846ef': 57, 'ada7a83c-e3e1-40f1-93f9-3e73dbc9298a': 49, '66c662b6-6e2f-4930-8610-912e24c63ed1': 1679, 'dcb03ce3-67a5-4eb3-b2d1-2a12d93a38f3': 45, '72ae6caf-4f9f-407e-8c70-8cd195df955c': 164, '14b22b4b-06d5-4b82-8284-29d29b58945f': 77}\n"
     ]
    }
   ],
   "source": [
    "# Examine the data\n",
    "print \"Number of users in train: \" + str(len(train_user_ids))\n",
    "print \"\"\n",
    "for user_id in train_user_ids[1:3]:\n",
    "    print train_data[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037790\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE THE NUMBER OF SONGS WE ARE ESTIMATING IN OUR TRIAN_TEST SAMPLE\n",
    "num_songs_estimating = 0\n",
    "\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        num_songs_estimating += 1\n",
    "        \n",
    "print num_songs_estimating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans - Let's Cluster the Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KM = sklearn.cluster.KMeans(n_clusters=5, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=37)\n",
    "# Calls fit and then predict\n",
    "predict = KM.fit_predict(profile_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The objective function: -211766.969515\n"
     ]
    }
   ],
   "source": [
    "print \"The objective function: %f\" % KM.score(profile_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 4 0 8 9 9 7 6]\n"
     ]
    }
   ],
   "source": [
    "# Examine the predicted clusters\n",
    "print predict[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep track of score\n",
    "\n",
    "### Indicators for basic params\n",
    "5 clusters: -4578883.573153\n",
    "10 clusters: -948858.492895\n",
    "20 clusters: -448359.382828\n",
    "25 clusters:  -372704.076086\n",
    "\n",
    "### Better indicator columns for age:\n",
    "5 clusters: -211766.969515\n",
    "10 clusters: -170864.058997\n",
    "20 clusters: -129169.230617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test different techniques\n",
    "\n",
    "### GLOBAL & PER-USER MEDIANS (GIVEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "MEAN ABSOLUTE ERROR 140.056850\n"
     ]
    }
   ],
   "source": [
    "abs_error = 0\n",
    "\n",
    "# TEST WITH GLOBAL and per-USER MEDIAN (GIVEN)\n",
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "artist_plays_array = {}\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "        \n",
    "        if artist not in artist_plays_array:\n",
    "            artist_plays_array[artist] = []\n",
    "        \n",
    "        artist_plays_array[artist].append(plays)\n",
    "        \n",
    "    user_medians[user] = np.median(np.array(user_plays))\n",
    "global_median = np.median(np.array(plays_array))\n",
    "    \n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        if user in user_medians:\n",
    "            prediction = user_medians[user]\n",
    "            abs_error += abs(prediction - plays) \n",
    "        else:\n",
    "            print \"User\", user, \"not in train_train data.\"\n",
    "            abs_error += abs(global_median - plays)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given with Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "User 1c38bd41dbb223394a0639fc401f47435a5d6aec not in train_train data.\n",
      "MEAN ABSOLUTE ERROR 146.564527\n"
     ]
    }
   ],
   "source": [
    "abs_error = 0\n",
    "\n",
    "# TEST WITH GLOBAL and per-USER MEDIAN (GIVEN)\n",
    "# Compute the global median and per-user median.\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "artist_plays_array = {}\n",
    "\n",
    "drop_ratio = .9\n",
    "\n",
    "cluster_plays_array = {}\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_plays = []\n",
    "    cluster_id = predict[user_pos_by_id[user]]\n",
    "    if cluster_id not in cluster_plays_array:\n",
    "        cluster_plays_array[cluster_id] = []\n",
    "    \n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "        \n",
    "        if artist not in artist_plays_array:\n",
    "            artist_plays_array[artist] = []\n",
    "        \n",
    "        artist_plays_array[artist].append(plays)\n",
    "        \n",
    "    user_median = np.median(np.array(user_plays))\n",
    "    user_medians[user] = user_median\n",
    "    cluster_plays_array[cluster_id].append(user_median)\n",
    "    \n",
    "global_median = np.median(np.array(plays_array))\n",
    "#global_mean = np.mean(np.array(plays_array))\n",
    "\n",
    "cluster_ratios = {}\n",
    "for cluster_id, cluster_data in cluster_plays_array.iteritems():\n",
    "    cluster_ratios[cluster_id] = np.median(cluster_data) / global_median\n",
    "\n",
    "artist_ratios = {}\n",
    "for artist, artist_data in artist_plays_array.iteritems():\n",
    "    #artist_ratios[artist] = np.median(artist_data) - global_median\n",
    "    artist_ratios[artist] = np.median(artist_data) / global_median\n",
    "    \n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    cluster_id = predict[user_pos_by_id[user]]\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        if user in user_medians:\n",
    "            prediction = user_medians[user] * artist_ratios[artist] * drop_ratio * cluster_ratios[cluster_id]\n",
    "            abs_error += abs(prediction - plays) \n",
    "        else:\n",
    "            print \"User\", user, \"not in train_train data.\"\n",
    "            abs_error += abs(global_median - plays)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-Occurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the co-occurance matrix\n",
    "artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    for artist_1, plays_1 in user_data.iteritems():\n",
    "        for artist_2, plays_2 in user_data.iteritems():\n",
    "            artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += plays_2 * 1.0 / plays_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalize!\n",
    "for i in range(len(artist_pos_by_id)):\n",
    "    norm_factor = artist_plays_cooccurance[i, i]\n",
    "    for j in range(len(artist_pos_by_id)):\n",
    "        artist_plays_cooccurance[i, j] /= norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   3.07399955e-03   8.87521764e-03   0.00000000e+00\n",
      "    1.43453312e-03   1.27317323e-02   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   7.16298438e-03]\n",
      " [  6.75186882e-04   1.00000000e+00   1.69967806e-03   0.00000000e+00\n",
      "    5.69809866e-03   1.19556844e-02   1.34698276e-03   0.00000000e+00\n",
      "    0.00000000e+00   7.89914463e-03]\n",
      " [  1.17247325e-02   7.46060576e-03   1.00000000e+00   0.00000000e+00\n",
      "    8.04970373e-03   1.01068096e-02   0.00000000e+00   0.00000000e+00\n",
      "    9.06927758e-04   1.44810334e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "    2.74996777e-03   1.80783336e-01   2.80500447e-02   2.28186664e-03\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.59123300e-03   9.52609249e-03   5.98537119e-04   1.37321853e-03\n",
      "    1.00000000e+00   8.43219707e-02   0.00000000e+00   0.00000000e+00\n",
      "    8.43420645e-03   0.00000000e+00]\n",
      " [  9.02590526e-04   9.52158720e-04   8.95830228e-04   1.14171383e-02\n",
      "    3.28545010e-03   1.00000000e+00   8.71032863e-03   1.47156724e-03\n",
      "    1.06374921e-02   6.10965113e-03]\n",
      " [  0.00000000e+00   1.33056133e-03   0.00000000e+00   4.31894044e-03\n",
      "    0.00000000e+00   2.33589567e-01   1.00000000e+00   0.00000000e+00\n",
      "    3.88241219e-02   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   1.80031347e-03\n",
      "    0.00000000e+00   1.44642864e-02   0.00000000e+00   1.00000000e+00\n",
      "    0.00000000e+00   7.32284822e-02]\n",
      " [  0.00000000e+00   0.00000000e+00   1.06859013e-03   0.00000000e+00\n",
      "    8.42281317e-04   1.04402705e-01   1.46946701e-02   0.00000000e+00\n",
      "    1.00000000e+00   7.65473626e-03]\n",
      " [  8.74393250e-04   1.91551180e-03   2.39503496e-03   0.00000000e+00\n",
      "    0.00000000e+00   2.13322315e-02   0.00000000e+00   3.18540599e-03\n",
      "    7.57308130e-04   1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print artist_plays_cooccurance[0:10,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User f283c15ed4180e686384dc1de2a5cbf5f95ae269 Actual:  3 Prediction:  1.13731897507\n",
      "User f283c15ed4180e686384dc1de2a5cbf5f95ae269 Actual:  3 Prediction:  1.19945053006\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c Actual:  415 Prediction:  5.33860637449\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c Actual:  327 Prediction:  37.7821565346\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c Actual:  306 Prediction:  18.0026577854\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c Actual:  376 Prediction:  12.3594019268\n",
      "User 0eae120959c04371c23af09abaf71305ab2a1b3c Actual:  306 Prediction:  2.46022292209\n",
      "User 0eae120959c04371c23af09abaf71305ab2a1b3c Actual:  170 Prediction:  4.46785056636\n",
      "User 0eae120959c04371c23af09abaf71305ab2a1b3c Actual:  248 Prediction:  7.35057333033\n",
      "User 734f7337c7d33e99fa60a6361a5df8e3fb939ecf Actual:  259 Prediction:  6.76629462309\n",
      "User 734f7337c7d33e99fa60a6361a5df8e3fb939ecf Actual:  304 Prediction:  7.54324370899\n",
      "User 734f7337c7d33e99fa60a6361a5df8e3fb939ecf Actual:  187 Prediction:  5.222965283\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee Actual:  114 Prediction:  9.95328528173\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee Actual:  132 Prediction:  2.94426549409\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee Actual:  580 Prediction:  88.966171817\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee Actual:  151 Prediction:  40.5015865716\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 Actual:  135 Prediction:  382.219580162\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 Actual:  1490 Prediction:  101.620919117\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 Actual:  187 Prediction:  81.0923879661\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 Actual:  96 Prediction:  22.0371894126\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 Actual:  331 Prediction:  128.177054651\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e Actual:  69 Prediction:  8.53453888095\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e Actual:  31 Prediction:  2.80237678438\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e Actual:  57 Prediction:  34.6262722055\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e Actual:  53 Prediction:  9.45974149083\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e Actual:  64 Prediction:  2.96678104553\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  111 Prediction:  1.5339227923\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  102 Prediction:  3.05968867306\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  213 Prediction:  8.63840801281\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  45 Prediction:  30.7070948187\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  436 Prediction:  7.5884235241\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba Actual:  40 Prediction:  27.2191201665\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  113 Prediction:  47.4157622811\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  198 Prediction:  0.528277631011\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  311 Prediction:  2.33407339401\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  187 Prediction:  20.0005264041\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  140 Prediction:  0.48799898462\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 Actual:  253 Prediction:  7.74811000265\n",
      "MEAN ABSOLUTE ERROR 230.156723\n"
     ]
    }
   ],
   "source": [
    "abs_error = 0\n",
    "\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "user_total_plays = {}\n",
    "artist_plays_array = {}\n",
    "\n",
    "drop_ratio = 1.0\n",
    "\n",
    "cluster_plays_array = {}\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_plays = []\n",
    "    #cluster_id = predict[user_pos_by_id[user]]\n",
    "    #if cluster_id not in cluster_plays_array:\n",
    "    #    cluster_plays_array[cluster_id] = []\n",
    "    \n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "        \n",
    "        if artist not in artist_plays_array:\n",
    "            artist_plays_array[artist] = []\n",
    "        \n",
    "        artist_plays_array[artist].append(plays)\n",
    "        \n",
    "    user_median = np.median(np.array(user_plays))\n",
    "    user_medians[user] = user_median\n",
    "    user_total_plays[user] = np.sum(user_plays)\n",
    "#    cluster_plays_array[cluster_id].append(user_median)\n",
    "    \n",
    "global_median = np.median(np.array(plays_array))\n",
    "#global_mean = np.mean(np.array(plays_array))\n",
    "\n",
    "#cluster_ratios = {}\n",
    "#for cluster_id, cluster_data in cluster_plays_array.iteritems():\n",
    "#    cluster_ratios[cluster_id] = np.median(cluster_data) / global_median\n",
    "\n",
    "artist_ratios = {}\n",
    "for artist, artist_data in artist_plays_array.iteritems():\n",
    "    #artist_ratios[artist] = np.median(artist_data) - global_median\n",
    "    artist_ratios[artist] = np.median(artist_data) / global_median\n",
    "    \n",
    "itr = 0\n",
    "    \n",
    "# PREDICT!\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    itr += 1\n",
    "    \n",
    "    #cluster_id = predict[user_pos_by_id[user]]\n",
    "    if user in user_total_plays:\n",
    "        user_total = user_total_plays[user]\n",
    "        user_train = train_train_data[user]\n",
    "    \n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "            prediction = 0\n",
    "            for artist_cooccur, plays_cooccur in user_train.iteritems():\n",
    "                prediction += (1.0 * plays_cooccur / user_total) * (plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist_to_predict]])\n",
    "        \n",
    "            #prediction = user_medians[user] * artist_ratios[artist] * drop_ratio * cluster_ratios[cluster_id]\n",
    "            abs_error += abs(prediction - plays_to_predict) \n",
    "            if itr < 10:\n",
    "                print \"User\", user, \"Actual: \", plays_to_predict, \"Prediction: \", prediction\n",
    "\n",
    "    else:\n",
    "        print \"User\", user, \"not in train_train data.\"\n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "            abs_error += abs(global_median - plays_to_predict)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "User f283c15ed4180e686384dc1de2a5cbf5f95ae269 TRAIN:  {'79239441-bfd5-4981-a70c-55c3f15c1287': 5, '020bfbb4-05c3-4c86-b372-17825c262094': 10, 'c3cceeed-3332-4cf0-8c4c-bbde425147b6': 8, 'c98d40fd-f6cf-4b26-883e-eaa515ee2851': 10, '7944ed53-2a58-4035-9b93-140a71e41c34': 3, '1a1cd7f3-e5df-4eca-bae2-2757c9e656b5': 3, 'c2c70ed6-5f10-445c-969f-2c16bc9a4c2e': 24, '2fa0d3ac-b64c-401a-b0a1-4915ba6cc157': 11, '092ca127-2e07-4cbd-9cba-e412b4ddddd9': 4, '83d91898-7763-47d7-b03b-b92132375c47': 66, 'd1353a0c-26fb-4318-a116-defde9c7c9ad': 3, 'e83144dd-bb95-49fe-b1dd-00bab25cca9e': 11, '847e8a0c-cc20-4213-9e16-975515c2a926': 4, 'd87e52c5-bb8d-4da8-b941-9f4928627dc8': 8}\n",
      "Actual:  3 Prediction:  7.51435190079 False predict:  0.785879751963\n",
      "Actual:  3 Prediction:  7.61676936799 False predict:  1.04192341998\n",
      "------\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c TRAIN:  {'298909e4-ebcb-47b8-95e9-cc53b087fc65': 337, 'e6e879c0-3d56-4f12-b3c5-3ce459661a8e': 427, 'ba0d6274-db14-4ef5-b28d-657ebde1a396': 761, '606bf117-494f-4864-891f-09d63ff6aa4b': 445, 'cc197bad-dc9c-440d-a5b5-d52ba2e14234': 574, 'b847568f-cd75-44c7-b87b-4f38a5a9f661': 303, 'f6f2326f-6b25-4170-b89d-e235b25508e8': 361, 'c1e98e4a-4628-4c89-a7a6-0e0171600b05': 640, '0743b15a-3c32-48c8-ad58-cb325350befa': 382, '92dc699f-fcbc-4278-afbe-40b5ad060a55': 305, 'ef90f210-f136-4386-ab37-8c00d04eeace': 357}\n",
      "Actual:  415 Prediction:  345.026279989 False predict:  3.06569997363\n",
      "Actual:  327 Prediction:  354.348345388 False predict:  26.3708634712\n",
      "Actual:  306 Prediction:  348.375779314 False predict:  11.4394482845\n",
      "Actual:  376 Prediction:  346.967695841 False predict:  7.91923960183\n",
      "------\n",
      "User 0eae120959c04371c23af09abaf71305ab2a1b3c TRAIN:  {'8538e728-ca0b-4321-b7e5-cff6565dd4c0': 205, '42faad37-8aaa-42e4-a300-5a7dae79ed24': 177, '83d91898-7763-47d7-b03b-b92132375c47': 184, 'cc433a77-176b-4d02-857b-2bfb68b3219c': 160, 'a2accb58-6099-4cb5-a3c8-f6332f364db5': 239, '14b22b4b-06d5-4b82-8284-29d29b58945f': 455, '3f542031-b054-454d-b57b-812fa2a81b11': 236, '9d4c4835-c71a-4647-a4fc-263e26832cd0': 473, 'e664d1cd-23ab-48d5-b8fa-e98485daa5be': 439, '0a77bec1-12ef-4caa-b36a-f533001fcd29': 154, 'b7ddce8b-9e5c-46bd-9d33-41b134ce1a7f': 178, 'a3cb23fc-acd3-4ce0-8f36-1e5aa6a18432': 418, '7b1cf87e-c54f-4abc-893d-90245a31900d': 190}\n",
      "Actual:  306 Prediction:  185.052757915 False predict:  1.38189478716\n",
      "Actual:  170 Prediction:  185.689302269 False predict:  2.97325567162\n",
      "Actual:  248 Prediction:  186.572696497 False predict:  5.18174124131\n",
      "------\n",
      "User 734f7337c7d33e99fa60a6361a5df8e3fb939ecf TRAIN:  {'cd8c5019-5d75-4d5c-bc28-e1e26a7dd5c8': 177, '3f8a5e5b-c24b-4068-9f1c-afad8829e06b': 242, '1cc5adcd-1422-4b5c-a3cd-3ecd4f43f506': 262, '10adbe5e-a2c0-4bf3-8249-2b4cbf6e6ca8': 373, 'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d': 307, '8247a3f2-3a8e-4256-b322-6c57b03a4e36': 181, '979d01bc-a4da-4c80-8cc1-be40bd35cd5e': 415, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 779}\n",
      "Actual:  259 Prediction:  257.554481924 False predict:  3.76120481016\n",
      "Actual:  304 Prediction:  257.936790197 False predict:  4.71697549247\n",
      "Actual:  187 Prediction:  257.557933288 False predict:  3.76983322033\n",
      "------\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee TRAIN:  {'3997d4a6-c2bd-4191-8406-eb07f0abb5d2': 173, '847e8284-8582-4b0e-9c26-b042a4f49e57': 206, '4f8ef4a3-40fa-46b5-8773-97686a8424f4': 276, '6e9ac29b-798c-4af7-8d9e-55cdc72a999c': 948, '896f0194-8ab2-4278-81e0-c56a0444b569': 255, '2944824d-4c26-476f-a981-be849081942f': 253, 'd43d12a1-2dc9-4257-a2fd-0a3bb1081b86': 119, '4bdcee62-4902-4773-8cd1-e252e2e31225': 1360, '73e5e69d-3554-40d8-8516-00cb38737a1c': 143, '0110e63e-0a9b-4818-af8e-41e180c20b9a': 113, '057aa66c-cf6e-499d-bda8-5adc47ad4197': 353, '3ff72a59-f39d-411d-9f93-2d4a86413013': 1193, 'f47fc54d-b334-4321-8218-00c5b11d4dd1': 532}\n",
      "Actual:  114 Prediction:  232.160000413 False predict:  6.65000103146\n",
      "Actual:  132 Prediction:  230.093372852 False predict:  1.48343213083\n",
      "Actual:  580 Prediction:  258.096200291 False predict:  71.4905007267\n",
      "Actual:  151 Prediction:  242.431849877 False predict:  32.3296246919\n",
      "------\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 TRAIN:  {'3f2a12e9-6398-42fd-b257-2f6abd4aa5fc': 276, '144ef525-85e9-40c3-8335-02c32d0861f3': 561, 'dfe9a7c4-8cf2-47f4-9dcb-d233c2b86ec3': 93, '2386cd66-e923-4e8e-bf14-2eebe2e9b973': 336, '788ad31c-bf0c-4a31-83f8-b8b130d79c76': 150, '020bfbb4-05c3-4c86-b372-17825c262094': 96, 'bc710bcf-8815-42cf-bad2-3f1d12246aeb': 452, '25a757f1-9fbe-4c52-be2e-1a5294fb25b9': 275, '39ab1aed-75e0-4140-bd47-540276886b60': 180, '3d2b98e5-556f-4451-a3ff-c50ea18d57cb': 153, '8bfac288-ccc5-448d-9573-c33ea2aa5c30': 186, 'ebee61b4-bbdd-4087-9bcb-d5aa099088ec': 3923, 'f90575d1-abcb-42b3-ae32-1849312c26e6': 148}\n",
      "Actual:  135 Prediction:  276.2262272 True predict:  272.065568001\n",
      "Actual:  1490 Prediction:  192.74222396 False predict:  63.3555599009\n",
      "Actual:  187 Prediction:  192.653225337 False predict:  63.1330633418\n",
      "Actual:  96 Prediction:  175.143379155 False predict:  19.3584478873\n",
      "Actual:  331 Prediction:  202.347347439 False predict:  87.3683685967\n",
      "------\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e TRAIN:  {'3f2a12e9-6398-42fd-b257-2f6abd4aa5fc': 439, '8ac6cc32-8ddf-43b1-9ac4-4b04f9053176': 48, 'ffb390b8-8df4-4b72-97d1-7b2fc008a452': 219, 'ab7ebf8c-059f-4071-93b1-dd3ae80d60b2': 46, '4c01333f-e8e8-43bd-9923-8de83ef6f63d': 45, 'a0327dc2-dc76-44d5-aec6-47cd2dff1469': 34, 'c07f0676-9143-4217-8a9f-4c26bd636f13': 39, 'd6e65033-b56a-49df-8744-6fc3ffd75edd': 337, '1fda852b-92e9-4562-82fa-c52820a77b23': 36, 'f0e820ab-f31a-400d-9c5e-8be1c8c38726': 78, '596ffa74-3d08-44ef-b113-765d43d12738': 53}\n",
      "Actual:  69 Prediction:  45.6952508558 False predict:  6.23812713959\n",
      "Actual:  31 Prediction:  43.9412160144 False predict:  1.85304003602\n",
      "Actual:  57 Prediction:  53.8201696537 False predict:  26.5504241344\n",
      "Actual:  53 Prediction:  45.6264356329 False predict:  6.06608908213\n",
      "Actual:  64 Prediction:  43.987059475 False predict:  1.96764868752\n",
      "------\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba TRAIN:  {'cb2972b9-29d1-4d47-b5a8-51e1035a6003': 46, '61cd6f2a-cdde-4f34-aacd-b992badcacba': 35, 'cc197bad-dc9c-440d-a5b5-d52ba2e14234': 78, 'ef6a8aab-9dfe-46ac-a225-67df4601ad69': 51, 'b7ddce8b-9e5c-46bd-9d33-41b134ce1a7f': 49, '35a6a353-b186-4c13-a264-d18d5e2ce853': 460, '503877b0-4e1b-452b-851c-5e3f478d3714': 321, 'b3b5ceef-0d3e-4191-a621-5e97d6ed3d97': 37, '12d432a3-feb0-49b1-a107-d20751880764': 78, '14e410f5-97f2-48ba-b1f7-a3a44cbea05c': 45, '1b0b533e-9a62-4a95-9c68-f2e140dde9da': 32, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 47}\n",
      "Actual:  111 Prediction:  43.490971573 False predict:  0.727428932459\n",
      "Actual:  102 Prediction:  44.2206755247 False predict:  2.55168881182\n",
      "Actual:  213 Prediction:  45.9472908491 False predict:  6.86822712287\n",
      "Actual:  45 Prediction:  52.2514571912 False predict:  22.628642978\n",
      "Actual:  436 Prediction:  44.9831372921 False predict:  4.45784323033\n",
      "Actual:  40 Prediction:  51.9315478605 False predict:  21.8288696512\n",
      "------\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 TRAIN:  {'7bf1f441-ccf1-4258-9797-07c8d16eb44c': 203, '1c70a3fc-fa3c-4be1-8b55-c3192db8a884': 135, '13655113-cd16-4b43-9dca-cadbbf26ee05': 130, '8c538f11-c141-4588-8ecb-931083524186': 116, '99e9b8ff-b8ea-4019-a073-acc9fbc93bbe': 193, '4236d929-9a81-4c8e-97c3-8d3306780f50': 158}\n",
      "Actual:  113 Prediction:  148.355036606 False predict:  41.262591514\n",
      "Actual:  198 Prediction:  131.984250526 False predict:  0.335626314072\n",
      "Actual:  311 Prediction:  132.481266271 False predict:  1.57816567836\n",
      "Actual:  187 Prediction:  139.52697046 False predict:  19.1924261492\n",
      "Actual:  140 Prediction:  131.933424033 False predict:  0.208560083044\n",
      "Actual:  253 Prediction:  134.211796713 False predict:  5.90449178323\n",
      "MEAN ABSOLUTE ERROR 138.860687\n"
     ]
    }
   ],
   "source": [
    "# Construct the co-occurance matrix\n",
    "artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    for i, (artist_1, plays_1) in enumerate(user_data.iteritems()):\n",
    "        for j, (artist_2, plays_2) in enumerate(user_data.iteritems()):\n",
    "            if j > i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += plays_2 / plays_1\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += plays_1 / plays_2\n",
    "            elif j==i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_1]] += 1\n",
    "            \n",
    "# Normalize!\n",
    "for i in range(len(artist_pos_by_id)):\n",
    "    norm_factor = artist_plays_cooccurance[i, i]\n",
    "    for j in range(len(artist_pos_by_id)):\n",
    "        artist_plays_cooccurance[i, j] /= norm_factor\n",
    "\n",
    "itr = 0\n",
    "abs_error = 0\n",
    "    \n",
    "# PREDICT!\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    itr += 1\n",
    "    \n",
    "    #cluster_id = predict[user_pos_by_id[user]]\n",
    "    if user in user_total_plays:\n",
    "        user_total = user_total_plays[user]\n",
    "        user_train = train_train_data[user]\n",
    "        if itr < 10:\n",
    "            print \"------\"\n",
    "            print \"User\", user, \"TRAIN: \", user_train\n",
    "    \n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "#            prediction = []\n",
    "            prediction = 0\n",
    "            for artist_cooccur, plays_cooccur in user_train.iteritems():\n",
    "                #if plays_cooccur > 1:\n",
    "                    #prediction.append(plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist_to_predict]])\n",
    "                prediction += 1.0*plays_cooccur/user_total * (plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist_to_predict]])\n",
    "        \n",
    "            #if len(prediction) > 0:\n",
    "            #    prediction = np.mean(prediction)#1.0 * prediction / user_total\n",
    "            #else:\n",
    "            #    prediction = 1.0\n",
    "            w_prediction = user_medians[user] * .9 + prediction * .4\n",
    "            #prediction = prediction# * user_medians[user]* artist_ratios[artist]\n",
    "            #user_medians[user] * artist_ratios[artist] * drop_ratio * cluster_ratios[cluster_id]\n",
    "            abs_error += abs(w_prediction - plays_to_predict) \n",
    "            if itr < 10:\n",
    "                print \"Actual: \", plays_to_predict, \"Prediction: \", w_prediction, (prediction > plays_to_predict), \"predict: \", prediction\n",
    "\n",
    "    else:\n",
    "        print \"User\", user, \"not in train_train data.\"\n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "            abs_error += abs(global_median - plays_to_predict)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cooccurance by ratio to user median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abs_error = 0\n",
    "\n",
    "plays_array  = []\n",
    "user_medians = {}\n",
    "user_means = {}\n",
    "user_total_plays = {}\n",
    "user_stds = {}\n",
    "artist_plays_array = {}\n",
    "\n",
    "cluster_plays_array = {}\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_plays = []\n",
    "    #cluster_id = predict[user_pos_by_id[user]]\n",
    "    #if cluster_id not in cluster_plays_array:\n",
    "    #    cluster_plays_array[cluster_id] = []\n",
    "    \n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "        \n",
    "        if artist not in artist_plays_array:\n",
    "            artist_plays_array[artist] = []\n",
    "        \n",
    "        artist_plays_array[artist].append(plays)\n",
    "        \n",
    "    user_median = np.median(np.array(user_plays))\n",
    "    user_medians[user] = user_median\n",
    "    user_means[user] = np.mean(user_plays)\n",
    "    user_stds[user] = np.std(user_plays)\n",
    "    user_total_plays[user] = np.sum(user_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct the co-occurance matrix - METHOD 1\n",
    "artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_median = user_medians[user]\n",
    "    user_mean = user_means[user]\n",
    "    user_std = user_stds[user]\n",
    "    if user_std == 0:\n",
    "        user_std = 1.0\n",
    "    for i, (artist_1, plays_1) in enumerate(user_data.iteritems()):\n",
    "        for j, (artist_2, plays_2) in enumerate(user_data.iteritems()):\n",
    "            if j > i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += (1.0 * plays_2 - user_median) / user_std\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += (1.0 * plays_1 - user_median) / user_std\n",
    "            elif j==i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_1]] += 1#(1.0 * plays_1 - user_mean) / user_mean\n",
    "            \n",
    "# Normalize!\n",
    "for i in range(len(artist_pos_by_id)):\n",
    "    norm_factor = artist_plays_cooccurance[i, i]\n",
    "    for j in range(len(artist_pos_by_id)):\n",
    "        artist_plays_cooccurance[i, j] /= norm_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct the co-occurance matrix - METHOD 2\n",
    "artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "user_cooccurance_counts = np.ones((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "user_cooccurance_counts = user_cooccurance_counts * .01\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    user_median = user_medians[user]\n",
    "    user_mean = user_means[user]\n",
    "    user_std = user_stds[user]\n",
    "    if user_std == 0:\n",
    "        user_std = 1.0\n",
    "    for i, (artist_1, plays_1) in enumerate(user_data.iteritems()):\n",
    "        for j, (artist_2, plays_2) in enumerate(user_data.iteritems()):\n",
    "            if j > i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += (1.0 * plays_2 - user_mean) / user_std\n",
    "                user_cooccurance_counts[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += 1.0\n",
    "                \n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += (1.0 * plays_1 - user_mean) / user_std\n",
    "                user_cooccurance_counts[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += 1.0\n",
    "                \n",
    "            elif j==i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_1]] += 1#(1.0 * plays_1 - user_mean) / user_mean\n",
    "            \n",
    "# Normalize!\n",
    "for i in range(len(artist_pos_by_id)):\n",
    "    for j in range(len(artist_pos_by_id)):\n",
    "        artist_plays_cooccurance[i, j] /= user_cooccurance_counts[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "User f283c15ed4180e686384dc1de2a5cbf5f95ae269 TRAIN:  {'79239441-bfd5-4981-a70c-55c3f15c1287': 5, '020bfbb4-05c3-4c86-b372-17825c262094': 10, 'c3cceeed-3332-4cf0-8c4c-bbde425147b6': 8, 'c98d40fd-f6cf-4b26-883e-eaa515ee2851': 10, '7944ed53-2a58-4035-9b93-140a71e41c34': 3, '1a1cd7f3-e5df-4eca-bae2-2757c9e656b5': 3, 'c2c70ed6-5f10-445c-969f-2c16bc9a4c2e': 24, '2fa0d3ac-b64c-401a-b0a1-4915ba6cc157': 11, '092ca127-2e07-4cbd-9cba-e412b4ddddd9': 4, '83d91898-7763-47d7-b03b-b92132375c47': 66, 'd1353a0c-26fb-4318-a116-defde9c7c9ad': 3, 'e83144dd-bb95-49fe-b1dd-00bab25cca9e': 11, '847e8a0c-cc20-4213-9e16-975515c2a926': 4, 'd87e52c5-bb8d-4da8-b941-9f4928627dc8': 8}\n",
      "Actual:  3 Prediction:  8.09270817984 , Medians:  6.5 predict:  -0.0103884670325 -0.0675250357111\n",
      "Actual:  3 Prediction:  8.15426466244 , Medians:  6.5 predict:  -0.00632291874464 -0.0410989718402\n",
      "------\n",
      "User 5909125332c108365a26ccf0ee62636eee08215c TRAIN:  {'298909e4-ebcb-47b8-95e9-cc53b087fc65': 337, 'e6e879c0-3d56-4f12-b3c5-3ce459661a8e': 427, 'ba0d6274-db14-4ef5-b28d-657ebde1a396': 761, '606bf117-494f-4864-891f-09d63ff6aa4b': 445, 'cc197bad-dc9c-440d-a5b5-d52ba2e14234': 574, 'b847568f-cd75-44c7-b87b-4f38a5a9f661': 303, 'f6f2326f-6b25-4170-b89d-e235b25508e8': 361, 'c1e98e4a-4628-4c89-a7a6-0e0171600b05': 640, '0743b15a-3c32-48c8-ad58-cb325350befa': 382, '92dc699f-fcbc-4278-afbe-40b5ad060a55': 305, 'ef90f210-f136-4386-ab37-8c00d04eeace': 357}\n",
      "Actual:  415 Prediction:  297.692412398 , Medians:  376.0 predict:  -0.138781762107 -52.1819425522\n",
      "Actual:  327 Prediction:  321.699070486 , Medians:  376.0 predict:  0.0452121737471 16.9997773289\n",
      "Actual:  306 Prediction:  309.723911697 , Medians:  376.0 predict:  -0.0465688892414 -17.5099023548\n",
      "Actual:  376 Prediction:  299.254209309 , Medians:  376.0 predict:  -0.126811701149 -47.6811996319\n",
      "------\n",
      "User 0eae120959c04371c23af09abaf71305ab2a1b3c TRAIN:  {'8538e728-ca0b-4321-b7e5-cff6565dd4c0': 205, '42faad37-8aaa-42e4-a300-5a7dae79ed24': 177, '83d91898-7763-47d7-b03b-b92132375c47': 184, 'cc433a77-176b-4d02-857b-2bfb68b3219c': 160, 'a2accb58-6099-4cb5-a3c8-f6332f364db5': 239, '14b22b4b-06d5-4b82-8284-29d29b58945f': 455, '3f542031-b054-454d-b57b-812fa2a81b11': 236, '9d4c4835-c71a-4647-a4fc-263e26832cd0': 473, 'e664d1cd-23ab-48d5-b8fa-e98485daa5be': 439, '0a77bec1-12ef-4caa-b36a-f533001fcd29': 154, 'b7ddce8b-9e5c-46bd-9d33-41b134ce1a7f': 178, 'a3cb23fc-acd3-4ce0-8f36-1e5aa6a18432': 418, '7b1cf87e-c54f-4abc-893d-90245a31900d': 190}\n",
      "Actual:  306 Prediction:  183.612716466 , Medians:  220.5 predict:  -0.132037217754 -29.1142065148\n",
      "Actual:  170 Prediction:  182.529412537 , Medians:  220.5 predict:  -0.141726534215 -31.2507007944\n",
      "Actual:  248 Prediction:  200.326791235 , Medians:  220.5 predict:  0.017457264233 3.84932676338\n",
      "------\n",
      "User 734f7337c7d33e99fa60a6361a5df8e3fb939ecf TRAIN:  {'cd8c5019-5d75-4d5c-bc28-e1e26a7dd5c8': 177, '3f8a5e5b-c24b-4068-9f1c-afad8829e06b': 242, '1cc5adcd-1422-4b5c-a3cd-3ecd4f43f506': 262, '10adbe5e-a2c0-4bf3-8249-2b4cbf6e6ca8': 373, 'b10bbbfc-cf9e-42e0-be17-e2c3e1d2600d': 307, '8247a3f2-3a8e-4256-b322-6c57b03a4e36': 181, '979d01bc-a4da-4c80-8cc1-be40bd35cd5e': 415, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 779}\n",
      "Actual:  259 Prediction:  217.782254842 , Medians:  262.0 predict:  -0.121832534808 -31.9201241197\n",
      "Actual:  304 Prediction:  195.942532552 , Medians:  262.0 predict:  -0.255543444973 -66.9523825829\n",
      "Actual:  187 Prediction:  236.94605214 , Medians:  262.0 predict:  -0.00450463361501 -1.18021400713\n",
      "------\n",
      "User e7dde2f288c7b2fe346f9636cfc8fc34f0872aee TRAIN:  {'3997d4a6-c2bd-4191-8406-eb07f0abb5d2': 173, '847e8284-8582-4b0e-9c26-b042a4f49e57': 206, '4f8ef4a3-40fa-46b5-8773-97686a8424f4': 276, '6e9ac29b-798c-4af7-8d9e-55cdc72a999c': 948, '896f0194-8ab2-4278-81e0-c56a0444b569': 255, '2944824d-4c26-476f-a981-be849081942f': 253, 'd43d12a1-2dc9-4257-a2fd-0a3bb1081b86': 119, '4bdcee62-4902-4773-8cd1-e252e2e31225': 1360, '73e5e69d-3554-40d8-8516-00cb38737a1c': 143, '0110e63e-0a9b-4818-af8e-41e180c20b9a': 113, '057aa66c-cf6e-499d-bda8-5adc47ad4197': 353, '3ff72a59-f39d-411d-9f93-2d4a86413013': 1193, 'f47fc54d-b334-4321-8218-00c5b11d4dd1': 532}\n",
      "Actual:  114 Prediction:  224.936909597 , Medians:  253.0 predict:  -0.207677646484 -52.5424445605\n",
      "Actual:  132 Prediction:  193.280491466 , Medians:  253.0 predict:  -0.290353895757 -73.4595356265\n",
      "Actual:  580 Prediction:  435.890605206 , Medians:  253.0 predict:  0.343264669581 86.8459614039\n",
      "Actual:  151 Prediction:  315.782963365 , Medians:  253.0 predict:  0.0295826448039 7.48440913539\n",
      "------\n",
      "User d44211611e177003d7ddad04961cc6af0cafa4c7 TRAIN:  {'3f2a12e9-6398-42fd-b257-2f6abd4aa5fc': 276, '144ef525-85e9-40c3-8335-02c32d0861f3': 561, 'dfe9a7c4-8cf2-47f4-9dcb-d233c2b86ec3': 93, '2386cd66-e923-4e8e-bf14-2eebe2e9b973': 336, '788ad31c-bf0c-4a31-83f8-b8b130d79c76': 150, '020bfbb4-05c3-4c86-b372-17825c262094': 96, 'bc710bcf-8815-42cf-bad2-3f1d12246aeb': 452, '25a757f1-9fbe-4c52-be2e-1a5294fb25b9': 275, '39ab1aed-75e0-4140-bd47-540276886b60': 180, '3d2b98e5-556f-4451-a3ff-c50ea18d57cb': 153, '8bfac288-ccc5-448d-9573-c33ea2aa5c30': 186, 'ebee61b4-bbdd-4087-9bcb-d5aa099088ec': 3923, 'f90575d1-abcb-42b3-ae32-1849312c26e6': 148}\n",
      "Actual:  135 Prediction:  386.996476742 , Medians:  186.5 predict:  0.010334759662 1.92743267696\n",
      "Actual:  1490 Prediction:  318.986634398 , Medians:  186.5 predict:  -0.0663709453446 -12.3781813068\n",
      "Actual:  187 Prediction:  454.205192819 , Medians:  186.5 predict:  0.0861369049335 16.0645327701\n",
      "Actual:  96 Prediction:  753.522424377 , Medians:  186.5 predict:  0.423725384423 79.0247841949\n",
      "Actual:  331 Prediction:  296.826446313 , Medians:  186.5 predict:  -0.0913645755547 -17.0394933409\n",
      "------\n",
      "User e4c6b36e65db3d48474dd538fe74d2dbb5a2e79e TRAIN:  {'3f2a12e9-6398-42fd-b257-2f6abd4aa5fc': 439, '8ac6cc32-8ddf-43b1-9ac4-4b04f9053176': 48, 'ffb390b8-8df4-4b72-97d1-7b2fc008a452': 219, 'ab7ebf8c-059f-4071-93b1-dd3ae80d60b2': 46, '4c01333f-e8e8-43bd-9923-8de83ef6f63d': 45, 'a0327dc2-dc76-44d5-aec6-47cd2dff1469': 34, 'c07f0676-9143-4217-8a9f-4c26bd636f13': 39, 'd6e65033-b56a-49df-8744-6fc3ffd75edd': 337, '1fda852b-92e9-4562-82fa-c52820a77b23': 36, 'f0e820ab-f31a-400d-9c5e-8be1c8c38726': 78, '596ffa74-3d08-44ef-b113-765d43d12738': 53}\n",
      "Actual:  69 Prediction:  56.4373152805 , Medians:  53.0 predict:  -0.177614737618 -9.41358109374\n",
      "Actual:  31 Prediction:  46.4454400577 , Medians:  53.0 predict:  -0.262885058094 -13.932908079\n",
      "Actual:  57 Prediction:  86.1402430253 , Medians:  53.0 predict:  0.0758690290841 4.02105854146\n",
      "Actual:  53 Prediction:  44.3054907461 , Medians:  53.0 predict:  -0.281147312129 -14.9008075429\n",
      "Actual:  64 Prediction:  46.0785083562 , Medians:  53.0 predict:  -0.266016440652 -14.0988713545\n",
      "------\n",
      "User b97479f9a563a5c43b423a976f51fd509e1ec5ba TRAIN:  {'cb2972b9-29d1-4d47-b5a8-51e1035a6003': 46, '61cd6f2a-cdde-4f34-aacd-b992badcacba': 35, 'cc197bad-dc9c-440d-a5b5-d52ba2e14234': 78, 'ef6a8aab-9dfe-46ac-a225-67df4601ad69': 51, 'b7ddce8b-9e5c-46bd-9d33-41b134ce1a7f': 49, '35a6a353-b186-4c13-a264-d18d5e2ce853': 460, '503877b0-4e1b-452b-851c-5e3f478d3714': 321, 'b3b5ceef-0d3e-4191-a621-5e97d6ed3d97': 37, '12d432a3-feb0-49b1-a107-d20751880764': 78, '14e410f5-97f2-48ba-b1f7-a3a44cbea05c': 45, '1b0b533e-9a62-4a95-9c68-f2e140dde9da': 32, '5441c29d-3602-4898-b1a1-b77fa23b8e50': 47}\n",
      "Actual:  111 Prediction:  58.9406448801 , Medians:  50.0 predict:  -0.250339719504 -12.5169859752\n",
      "Actual:  102 Prediction:  134.700734469 , Medians:  50.0 predict:  0.310622165452 15.5311082726\n",
      "Actual:  213 Prediction:  113.882369849 , Medians:  50.0 predict:  0.156473600923 7.82368004614\n",
      "Actual:  45 Prediction:  104.697321347 , Medians:  50.0 predict:  0.0884633576793 4.42316788397\n",
      "Actual:  436 Prediction:  70.137058614 , Medians:  50.0 predict:  -0.16743642059 -8.3718210295\n",
      "Actual:  40 Prediction:  112.468468282 , Medians:  50.0 predict:  0.146004435789 7.30022178947\n",
      "------\n",
      "User 3bb020df0ff376dfdded4d5e63e2d35a50b3c535 TRAIN:  {'7bf1f441-ccf1-4258-9797-07c8d16eb44c': 203, '1c70a3fc-fa3c-4be1-8b55-c3192db8a884': 135, '13655113-cd16-4b43-9dca-cadbbf26ee05': 130, '8c538f11-c141-4588-8ecb-931083524186': 116, '99e9b8ff-b8ea-4019-a073-acc9fbc93bbe': 193, '4236d929-9a81-4c8e-97c3-8d3306780f50': 158}\n",
      "Actual:  113 Prediction:  141.040808383 , Medians:  172.5 predict:  0.131667098567 22.7125745029\n",
      "Actual:  198 Prediction:  125.496897853 , Medians:  172.5 predict:  -0.142007306797 -24.4962604225\n",
      "Actual:  311 Prediction:  129.939698924 , Medians:  172.5 predict:  -0.0637849740727 -11.0029080275\n",
      "Actual:  187 Prediction:  137.513304391 , Medians:  172.5 predict:  0.0695599759266 11.9990958473\n",
      "Actual:  140 Prediction:  128.411600768 , Medians:  172.5 predict:  -0.0906894877978 -15.6439366451\n",
      "Actual:  253 Prediction:  134.379285917 , Medians:  172.5 predict:  0.0143807698729 2.48068280307\n",
      "MEAN ABSOLUTE ERROR 136.661990\n"
     ]
    }
   ],
   "source": [
    "itr = 0\n",
    "abs_error = 0\n",
    "\n",
    "drop_ratio = 1.0\n",
    "    \n",
    "# PREDICT!\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    itr += 1\n",
    "    \n",
    "    #cluster_id = predict[user_pos_by_id[user]]\n",
    "    if user in user_total_plays:\n",
    "        user_total = user_total_plays[user]\n",
    "        user_train = train_train_data[user]\n",
    "        if itr < 10:\n",
    "            print \"------\"\n",
    "            print \"User\", user, \"TRAIN: \", user_train\n",
    "    \n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "#            prediction = []\n",
    "            prediction = 0\n",
    "            for artist_cooccur, plays_cooccur in user_train.iteritems():\n",
    "                #if plays_cooccur > 1:\n",
    "                    #prediction.append(plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist_to_predict]])\n",
    "                prediction += (plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist_to_predict]])\n",
    "        \n",
    "            prediction = prediction / user_total\n",
    "        \n",
    "            #if len(prediction) > 0:\n",
    "            #    prediction = np.mean(prediction)#1.0 * prediction / user_total\n",
    "            #else:\n",
    "            #    prediction = 1.0\n",
    "            user_std = user_stds[user]\n",
    "            if user_std == 0:\n",
    "                user_std = 1.0\n",
    "            w_prediction = user_means[user] * .75 + user_std * prediction * 1\n",
    "            #prediction = prediction# * user_medians[user]* artist_ratios[artist]\n",
    "            #user_medians[user] * artist_ratios[artist] * drop_ratio * cluster_ratios[cluster_id]\n",
    "            abs_error += abs(w_prediction - plays_to_predict) \n",
    "            if itr < 10:\n",
    "                print \"Actual: \", plays_to_predict, \"Prediction: \", w_prediction, \", Medians: \", user_medians[user], \"predict: \", prediction, user_medians[user] * prediction\n",
    "\n",
    "    else:\n",
    "        print \"User\", user, \"not in train_train data.\"\n",
    "        for artist_to_predict, plays_to_predict in user_data.iteritems():\n",
    "            abs_error += abs(global_median - plays_to_predict)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished setting up cluster author play dictionary, running test now\n",
      "MEAN ABSOLUTE ERROR 199.005376\n"
     ]
    }
   ],
   "source": [
    "abs_error = 0\n",
    "\n",
    "cluster_artist_plays = {}\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    cluster_id = predict[user_pos_by_id[user]]\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        if cluster_id not in cluster_artist_plays:\n",
    "            cluster_artist_plays[cluster_id] = {}\n",
    "        \n",
    "        if artist not in cluster_artist_plays[cluster_id]:\n",
    "            cluster_artist_plays[cluster_id][artist] = []\n",
    "        \n",
    "        cluster_artist_plays[cluster_id][artist].append(plays)\n",
    "\n",
    "print \"Finished setting up cluster author play dictionary, running test now\"\n",
    "\n",
    "# Precalculate the cluster-artist medians\n",
    "cluster_artist_medians = {}\n",
    "for cluster_id, cluster_data in cluster_artist_plays.iteritems():\n",
    "    artist_medians = {}\n",
    "    for artist, plays in cluster_data.iteritems():\n",
    "        artist_medians[artist] = np.median(plays)\n",
    "    cluster_artist_medians[cluster_id] = artist_medians\n",
    "\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        cluster_id = predict[user_pos_by_id[user]]\n",
    "        \n",
    "        if artist in cluster_artist_plays[cluster_id]:\n",
    "            abs_error += abs(np.median(cluster_artist_plays[cluster_id][artist]) - plays)\n",
    "        elif user in user_medians:\n",
    "            abs_error += abs(user_medians[user] - plays)\n",
    "        else:\n",
    "            print \"User\", user, \"not in train_train data.\"\n",
    "            abs_error += abs(global_median - plays)\n",
    "            #print \"Cluster+Artist: \", cluster_id, artist, \"not in train_train data.\"\n",
    "            #abs_error += abs(0 - plays)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished setting up cluster author play dictionary, running test now\n",
      "MEAN ABSOLUTE ERROR 142.834053\n"
     ]
    }
   ],
   "source": [
    "abs_error = 0\n",
    "\n",
    "cluster_artist_plays = {}\n",
    "\n",
    "# The median number of per user per cluster\n",
    "cluster_user_plays = {}\n",
    "\n",
    "# The cluster medians\n",
    "cluster_medians = {}\n",
    "\n",
    "user_medians = {}\n",
    "\n",
    "drop_ratio = .8\n",
    "\n",
    "for user, user_data in train_train_data.iteritems():\n",
    "    cluster_id = predict[user_pos_by_id[user]]\n",
    "    user_plays = []\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        if cluster_id not in cluster_artist_plays:\n",
    "            cluster_artist_plays[cluster_id] = {}\n",
    "        \n",
    "        if artist not in cluster_artist_plays[cluster_id]:\n",
    "            cluster_artist_plays[cluster_id][artist] = []\n",
    "        \n",
    "        cluster_artist_plays[cluster_id][artist].append(plays)\n",
    "\n",
    "        user_plays.append(plays)\n",
    "\n",
    "    median = np.median(np.array(user_plays))\n",
    "    user_medians[user] = median\n",
    "    if cluster_id not in cluster_user_plays:\n",
    "        cluster_user_plays[cluster_id] = []\n",
    "    cluster_user_plays[cluster_id].append(median) \n",
    "    \n",
    "# Calculate per-cluster user median\n",
    "for cluster_id, user_plays in cluster_user_plays.iteritems():\n",
    "    cluster_medians[cluster_id] = np.median(user_plays)\n",
    "    \n",
    "user_ratios = {}\n",
    "    \n",
    "# Calculate the user-cluster play ratios\n",
    "for user_id, median_plays in user_medians.iteritems():\n",
    "    cluster_id = predict[user_pos_by_id[user_id]]\n",
    "    user_ratios[user_id] = 1.0 * median_plays / cluster_medians[cluster_id]\n",
    "        \n",
    "print \"Finished setting up cluster author play dictionary, running test now\"\n",
    "\n",
    "# Precalculate the cluster-artist medians\n",
    "cluster_artist_medians = {}\n",
    "for cluster_id, cluster_data in cluster_artist_plays.iteritems():\n",
    "    artist_medians = {}\n",
    "    for artist, plays in cluster_data.iteritems():\n",
    "        artist_medians[artist] = np.median(plays)\n",
    "    cluster_artist_medians[cluster_id] = artist_medians\n",
    "\n",
    "# PREDICT!\n",
    "for user, user_data in train_test_data.iteritems():\n",
    "    for artist, plays in user_data.iteritems():\n",
    "        cluster_id = predict[user_pos_by_id[user]]\n",
    "        if artist in cluster_artist_plays[cluster_id]:\n",
    "            user_ratio = 1.0\n",
    "            if user in user_ratios:\n",
    "                user_ratio = user_ratios[user]\n",
    "            prediction = user_ratio * cluster_artist_medians[cluster_id][artist] * drop_ratio\n",
    "            abs_error += abs(prediction - plays)\n",
    "        elif user in user_medians:\n",
    "            abs_error += abs(user_medians[user] - plays)\n",
    "        else:\n",
    "            print \"User\", user, \"not in train_train data.\"\n",
    "            abs_error += abs(global_median - plays)\n",
    "            \n",
    "print \"MEAN ABSOLUTE ERROR %f\" % (abs_error / num_songs_estimating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN ABSOLUTE ERROR\n",
    "\n",
    "### Given - Per-User\n",
    "Global + Per-User (Given): 140.056850 <br />\n",
    "\n",
    "Global + Per-User \\* Artist Ratio: 143.587490 <br />\n",
    "Global + Per-User + Artist Diff: 144.839260 <br />\n",
    "Global + Per-User + Artist Diff from Mean: 226.244328 <br />\n",
    "\n",
    "Global + Per-User \\* Artist Ratio \\* .5: 167.470407 <br />\n",
    "Global + Per-User \\* Artist Ratio \\* .8: 143.928421 <br />\n",
    "\n",
    "Global + Per-User \\* Artist Ratio \\* Cluster Ratio \\* .8: 148.776073 <br />\n",
    "Global + Per-User \\* Artist Ratio \\* Cluster Ratio \\* .9: 146.564527 <br />\n",
    "Global + Per-User \\* Artist Ratio \\* Cluster Ratio \\* 1.0: 146.716599 <br />\n",
    "Global + Per-User \\* Artist Ratio \\* Cluster Ratio \\* 1.1: 148.907204 <br />\n",
    "\n",
    "\n",
    "### KMeans Basic\n",
    "KMeans (10 clusters): 198.894616 <br />\n",
    "KMeans (20 clusters): 199.005376 <br />\n",
    "\n",
    "### Per-User Ratios\n",
    "KMeans (5 clusters) + per-user ratio: 147.278504  <br />\n",
    "KMeans (10 clusters) + per-user ratio: 148.038072 <br />\n",
    "KMeans (20 clusters) + per-user ratio: 149.274154 <br />\n",
    "KMeans (25 clusters) + per-user ratio: 149.667337 <br />\n",
    "KMeans (50 clusters) + per-user ratio: 153.856717 <br />\n",
    "\n",
    "### Better indicator Columns for Age\n",
    "KMeans (5 clusters): 147.080268 <br />\n",
    "KMeans (10 clusters): 148.013096 <br />\n",
    "KMeans (20 clusters): 149.802176 <br />\n",
    "\n",
    "### Drop Ratio\n",
    "KMeans (5 clusters) - 0.5: 161.433577 <br />\n",
    "KMeans (5 clusters) - 0.75: 143.388267 <br />\n",
    "KMeans (5 clusters) - 0.78: 142.834053 <br />\n",
    "KMeans (5 clusters) - 0.8: 142.630979 <br />\n",
    "KMeans (5 clusters) - 0.85: 142.679850 <br />\n",
    "KMeans (5 clusters) - 0.9: 143.476183 <br />\n",
    "KMeans (5 clusters) - 1.0: 147.080268 <br />\n",
    "KMeans (5 clusters) - 1.1: 152.970603 <br />\n",
    "\n",
    "### Cooccurance\n",
    "Basic Ratios: 230.245089 <br />\n",
    "Basic Sums: 198.822865 <br />\n",
    "Weighted .8 \\* Medians + .2 \\* Cooccurance: 140.940338 <br />\n",
    "Weighted .9 \\* Medians + .2 \\* Cooccurance: 138.739097 <br />\n",
    "Weighted .9 \\* Medians + .3 \\* Cooccurance: 138.727909 <br />\n",
    "\n",
    "Medians - Weighted .9 \\* Medians + .3 \\* Cooccurance: 138.830714 <br />\n",
    "Means - Weighted .9 \\* Medians + .3 \\* Cooccurance: 138.505556 <br />\n",
    "Means - Weighted .9 \\* Medians + .4 \\* Cooccurance: 138.294710 <br />\n",
    "// Means (1s removed) - Weighted .9 \\* Medians + .4 \\* Cooccurance: 138.295340 <br />\n",
    "\n",
    "Ratios to User Median: 138.678506 <br />\n",
    "Remove medians, medians + medians \\* ratios: 139.824810 <br />\n",
    "Remove medians, basic normalize, medians +  medians \\* ratios: 138.717073 <br />\n",
    "\n",
    "Remove means, means +  means \\* ratios: 163.837442 <br />\n",
    "Remove means, medians +  medians \\* ratios: 138.998152 <br />\n",
    "Remove means, medians +  means \\* ratios: 138.867155 <br />\n",
    "\n",
    "#### Standardizing\n",
    "Remove means / var, medians +  var \\* ratios: 203.059854 <br />\n",
    "Remove means / var, means +  var \\* ratios: 226.789675 <br />\n",
    "\n",
    "Remove means / std, medians +  std \\* ratios: 138.911128 <br />\n",
    "Remove medians / std, medians +  std \\* ratios: 138.840453 <br />\n",
    "\n",
    "#### Coocurrance Method 2\n",
    "Remove medians / std, .9 \\* medians +  1.1 \\* std \\* ratios: 140.448489 <br />\n",
    "Remove medians / std, 1.0 \\* medians +  1.0 \\* std \\* ratios: 142.306458 <br />\n",
    "Remove medians / std, 1.0 \\* medians +  1.2 \\* std \\* ratios: 140.362853 <br />\n",
    "Remove medians / std, .8 \\* medians +  1.1 \\* std \\* ratios:  138.770764 <br />\n",
    "Remove medians / std, .7 \\* medians +  1.1 \\* std \\* ratios:  139.731552 <br />\n",
    "\n",
    "Remove means / std, .8 \\* medians +  1.1 \\* std \\* ratios: 141.149339 <br />\n",
    "Remove means / std, .8 \\* means +  1.1 \\* std \\* ratios: 137.624492 <br />\n",
    "Remove means / std, .75 \\* means +  1.1 \\* std \\* ratios: 136.966472 <br />\n",
    "Remove means / std, .75 \\* means +  1 \\* std \\* ratios: 136.661990 <br /> \n",
    "SUBMITTED - ACTUAL: 143.34759 <br />\n",
    "\n",
    "Remove means / std, .7 \\* means +  1.1 \\* std \\* ratios: 137.486371 <br />\n",
    "Remove means / std, 1.0 \\* means +  1.0 \\* std \\* ratios: 149.710529 <br />\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plays_array  = []\n",
    "user_medians = {}\n",
    "user_means = {}\n",
    "user_total_plays = {}\n",
    "user_stds = {}\n",
    "artist_plays_array = {}\n",
    "cluster_plays_array = {}\n",
    "\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_plays = []\n",
    "    \n",
    "    for artist, plays in user_data.iteritems():\n",
    "        plays_array.append(plays)\n",
    "        user_plays.append(plays)\n",
    "        \n",
    "        if artist not in artist_plays_array:\n",
    "            artist_plays_array[artist] = []\n",
    "        \n",
    "        artist_plays_array[artist].append(plays)\n",
    "        \n",
    "    user_median = np.median(np.array(user_plays))\n",
    "    user_medians[user] = user_median\n",
    "    user_means[user] = np.mean(user_plays)\n",
    "    user_stds[user] = np.std(user_plays)\n",
    "    user_total_plays[user] = np.sum(user_plays)\n",
    "    \n",
    "# # Construct the co-occurance matrix\n",
    "# artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "\n",
    "# for user, user_data in train_data.iteritems():\n",
    "#     user_median = user_medians[user]\n",
    "#     user_mean = user_means[user]\n",
    "#     user_std = user_stds[user]\n",
    "#     if user_std == 0:\n",
    "#         user_std = 1.0\n",
    "#     for i, (artist_1, plays_1) in enumerate(user_data.iteritems()):\n",
    "#         for j, (artist_2, plays_2) in enumerate(user_data.iteritems()):\n",
    "#             if j > i:\n",
    "#                 artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += (1.0 * plays_2 - user_median) / user_std\n",
    "#                 artist_plays_cooccurance[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += (1.0 * plays_1 - user_median) / user_std\n",
    "#             elif j==i:\n",
    "#                 artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_1]] += 1\n",
    "            \n",
    "# # Normalize!\n",
    "# for i in range(len(artist_pos_by_id)):\n",
    "#     norm_factor = artist_plays_cooccurance[i, i]\n",
    "#     for j in range(len(artist_pos_by_id)):\n",
    "#         artist_plays_cooccurance[i, j] /= norm_factor\n",
    "\n",
    "# Construct the co-occurance matrix - METHOD 2\n",
    "artist_plays_cooccurance = np.zeros((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "user_cooccurance_counts = np.ones((len(artist_pos_by_id), len(artist_pos_by_id)))\n",
    "user_cooccurance_counts = user_cooccurance_counts * .01\n",
    "\n",
    "for user, user_data in train_data.iteritems():\n",
    "    user_median = user_medians[user]\n",
    "    user_mean = user_means[user]\n",
    "    user_std = user_stds[user]\n",
    "    if user_std == 0:\n",
    "        user_std = 1.0\n",
    "    for i, (artist_1, plays_1) in enumerate(user_data.iteritems()):\n",
    "        for j, (artist_2, plays_2) in enumerate(user_data.iteritems()):\n",
    "            if j > i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += (1.0 * plays_2 - user_mean) / user_std\n",
    "                user_cooccurance_counts[artist_pos_by_id[artist_1], artist_pos_by_id[artist_2]] += 1.0\n",
    "                \n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += (1.0 * plays_1 - user_mean) / user_std\n",
    "                user_cooccurance_counts[artist_pos_by_id[artist_2], artist_pos_by_id[artist_1]] += 1.0\n",
    "                \n",
    "            elif j==i:\n",
    "                artist_plays_cooccurance[artist_pos_by_id[artist_1], artist_pos_by_id[artist_1]] += 1\n",
    "            \n",
    "# Normalize!\n",
    "for i in range(len(artist_pos_by_id)):\n",
    "    for j in range(len(artist_pos_by_id)):\n",
    "        artist_plays_cooccurance[i, j] /= user_cooccurance_counts[i,j]\n",
    "    \n",
    "# PREDICT!\n",
    "# Write out test solutions.\n",
    "with open(test_file, 'r') as test_fh:\n",
    "    test_csv = csv.reader(test_fh, delimiter=',', quotechar='\"')\n",
    "    next(test_csv, None)\n",
    "\n",
    "    with open(soln_file, 'w') as soln_fh:\n",
    "        soln_csv = csv.writer(soln_fh,\n",
    "                              delimiter=',',\n",
    "                              quotechar='\"',\n",
    "                              quoting=csv.QUOTE_MINIMAL)\n",
    "        soln_csv.writerow(['Id', 'plays'])\n",
    "\n",
    "        for row in test_csv:\n",
    "            id     = row[0]\n",
    "            user   = row[1]\n",
    "            artist = row[2]\n",
    "\n",
    "            if user in user_total_plays:\n",
    "                user_total = user_total_plays[user]\n",
    "                user_train = train_data[user]\n",
    "\n",
    "                prediction = 0\n",
    "                for artist_cooccur, plays_cooccur in user_train.iteritems():\n",
    "                    prediction += (plays_cooccur * artist_plays_cooccurance[artist_pos_by_id[artist_cooccur], artist_pos_by_id[artist]])\n",
    "\n",
    "                prediction = prediction / user_total\n",
    "\n",
    "                user_std = user_stds[user]\n",
    "                if user_std == 0:\n",
    "                    user_std = 1.0\n",
    "                #w_prediction = user_medians[user] * .9 + user_std * prediction * 1.1\n",
    "                w_prediction = user_means[user] * .75 + user_std * prediction * 1\n",
    "                soln_csv.writerow([id, w_prediction])\n",
    "\n",
    "            else:\n",
    "                print \"User\", user, \"not in train data.\"\n",
    "                soln_csv.writerow([id, global_median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
